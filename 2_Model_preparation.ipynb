{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CorsiDanilo/big-data-computing-project/blob/main/2_Model_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e452Ydj7chNV"
      },
      "source": [
        "# Bitcoin price forecasting with PySpark\n",
        "## Big Data Computing final project - A.Y. 2022 - 2023\n",
        "Prof. Gabriele Tolomei\n",
        "\n",
        "MSc in Computer Science\n",
        "\n",
        "La Sapienza, University of Rome\n",
        "\n",
        "### Author\n",
        "Corsi Danilo - corsi.1742375@studenti.uniroma1.it\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkQaY6VAf4v_"
      },
      "source": [
        "# Global Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L7-8QQvKf5CR"
      },
      "outputs": [],
      "source": [
        "JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "GDRIVE_DIR = \"/content/drive\"\n",
        "\n",
        "GDRIVE_DATASET_RAW_DIR = GDRIVE_DIR + \"/MyDrive/BDC/project/datasets/raw\"\n",
        "GDRIVE_DATASET_TEMP_DIR = GDRIVE_DIR + \"/MyDrive/BDC/project/datasets/temp\"\n",
        "GDRIVE_DATASET_OUTPUT_DIR = GDRIVE_DIR + \"/MyDrive/BDC/project/datasets/output\"\n",
        "\n",
        "GDRIVE_DATASET_NAME = \"bitcoin_blockchain_data_1m\"\n",
        "GDRIVE_DATASET_NAME_EXT = \"/\" + GDRIVE_DATASET_NAME + \".csv\"\n",
        "\n",
        "GDRIVE_DATASET = GDRIVE_DATASET_RAW_DIR + GDRIVE_DATASET_NAME_EXT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTGTgzEqE3x"
      },
      "source": [
        "#  Import useful Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PX7xDYw4SvrB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtmWjQUVSvq2"
      },
      "source": [
        "# **Spark + Google Colab Setup** ❗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si82CaUYSvrA",
        "outputId": "f3371ae3-8b6c-40ad-d9d1-1ef6635df4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u372-ga~us1-0ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "# Alternatively, if you want to install a specific version of pyspark:\n",
        "#!pip install pyspark==3.2.1\n",
        "!pip install -U -q PyDrive # To use files that are stored in Google Drive directly (e.g., without downloading them from an external URL)\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: da sistemare ❗\n",
        "#General System Utilities\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "#Data Processing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import concat\n",
        "import matplotlib.pyplot as plt\n",
        "from fastai.tabular import *\n",
        "import six\n",
        "\n",
        "#Pyspark/SQL libs\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType, IntegerType, FloatType\n",
        "import seaborn as sns\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "#DS/DL Libs\n",
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression as sklearnLR\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, GRU\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "yc9rF0qR3S2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fhi5bmOeSvrB"
      },
      "outputs": [],
      "source": [
        "# Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '4G').\\\n",
        "                set('spark.driver.memory', '45G').\\\n",
        "                set('spark.driver.maxResultSize', '10G').\\\n",
        "                set(\"spark.kryoserializer.buffer.max\", \"1G\").\\\n",
        "                setAppName(\"BitcoinPriceForecasting\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au2-MqC-SvrB",
        "outputId": "7651c727-81e6-4a7b-c116-5ec340d38117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Point Colaboratory to our Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model preparation** ❗\n"
      ],
      "metadata": {
        "id": "Kx-BUiTt1HJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset into pyspark dataframe objects\n",
        "df = spark.read.load(GDRIVE_DATASET,\n",
        "                         format=\"csv\",\n",
        "                         sep=\",\",\n",
        "                         inferSchema=\"true\",\n",
        "                         header=\"true\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "B5y1hZlB4IBF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression models typically take in a single vector input, so we’ll need to vectorize all of our features into a single column. Thankfully, pyspark offers the VectorAssembler class to do just that.\n",
        "\n",
        "To build and compare performance of our three feature set sizes — 34 (all features, our baseline), 7 (relevant features), and 7 (RFE-selected features) — we’ll start by assembling 3 independent VectorAssemblers, 1 for each feature list:"
      ],
      "metadata": {
        "id": "M2IKddKQ1U2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = ['market-price', 'market-cap', 'total-bitcoins', 'trade-volume', 'blocks-size', 'avg-block-size', 'n-transactions-total', 'n-transactions-per-block', 'hash-rate', 'difficulty', 'miners-revenue', 'transaction-fees-usd', 'n-unique-addresses', 'n-transactions', 'estimated-transaction-volume-usd']\n",
        "rel_columns = ['market-cap', 'estimated-transaction-volume-usd', 'blocks-size', 'n-unique-addresses']\n",
        "selected_features_rfe = ['total-bitcoins', 'blocks-size', 'avg-block-size', 'n-transactions-per-block', 'miners-revenue', 'n-unique-addresses', 'n-transactions']\n",
        "\n",
        "dep_var = 'market-price'\n",
        "\n",
        "vectorAssembler = VectorAssembler(\n",
        "    inputCols = all_features,\n",
        "    outputCol = 'features')\n",
        "\n",
        "vectorAssembler2 = VectorAssembler(\n",
        "    inputCols = rel_columns,\n",
        "    outputCol = 'features')\n",
        "\n",
        "vectorAssembler3 = VectorAssembler(\n",
        "    inputCols = selected_features_rfe,\n",
        "    outputCol = 'features')\n"
      ],
      "metadata": {
        "id": "rN-eF-Z51XND"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the 3 Vectorized RDDs, we apply the transform on the data using each:\n"
      ],
      "metadata": {
        "id": "dMeiJnId6XZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#All columns featurized\n",
        "v_df = vectorAssembler.transform(df)\n",
        "v_df = v_df.select(['features', dep_var])\n",
        "v_df.show(3)\n",
        "\n",
        "#Relevant columns featurized\n",
        "v_rel_df = vectorAssembler2.transform(df)\n",
        "v_rel_df = v_rel_df.select(['features', dep_var])\n",
        "v_rel_df.show(3)\n",
        "\n",
        "#RFE-selected columns featurized\n",
        "v_sel_df = vectorAssembler3.transform(df)\n",
        "v_sel_df = v_sel_df.select(['features', dep_var])\n",
        "v_sel_df.show(3)"
      ],
      "metadata": {
        "id": "DhLfsPPq3i1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and calling the show method on each of the resulting RDDs yields the following vectorized inputs (X) and targets (y):\n",
        "\n",
        "Great! Now we can move on to partitioning each of these RDDs into training and test sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "E5m0CN4Y6Zei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a utility method for creating training and testing inputs and labels:\n",
        "\n"
      ],
      "metadata": {
        "id": "arEQ1qLV6cn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_data_builder(spark_df, part_index):\n",
        "  train_df = spark.createDataFrame(spark_df.toPandas()[:part_index])\n",
        "  valid_df = spark.createDataFrame(spark_df.toPandas()[part_index:])\n",
        "  return train_df, valid_df"
      ],
      "metadata": {
        "id": "LuyY8s-J5P6W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, we can easily create 3 data bunches. First, we ensure that all 3 RDDs we created in the previous step are indexed correctly, store the index of an 80/20 split in a variable called “valid_index” and partition the data accordingly:\n",
        "\n"
      ],
      "metadata": {
        "id": "156kqSuA6eAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v_df.index = df.toPandas().index\n",
        "v_rel_df.index = df.toPandas().index\n",
        "v_sel_df.index = df.toPandas().index\n",
        "\n",
        "valid_index =  int(v_df.toPandas().shape[0] * .8)\n",
        "\n",
        "btc_train_df, btc_test_df = regression_data_builder(v_df, valid_index)\n",
        "btc_rel_train_df, btc_rel_test_df = regression_data_builder(v_rel_df, valid_index)\n",
        "btc_sel_train_df, btc_sel_test_df = regression_data_builder(v_sel_df, valid_index)\n",
        "\n",
        "\n",
        "print(btc_train_df.toPandas().shape, btc_test_df.toPandas().shape)\n",
        "print(btc_rel_train_df.toPandas().shape, btc_rel_test_df.toPandas().shape)\n",
        "print(btc_sel_train_df.toPandas().shape, btc_sel_test_df.toPandas().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7DlHz5B75qwZ",
        "outputId": "b626a4b1-1b79-424b-8177-c1ea2f8b7612"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 516, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
            "    raise Py4JNetworkError(\n",
            "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning:\n",
            "\n",
            "Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "\n",
            "Exception ignored in: <function _xla_gc_callback at 0x7f5811389bd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n",
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 516, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
            "    raise Py4JNetworkError(\n",
            "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c1af1e3f7ebf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mv_rel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mv_sel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalid_index\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_timedelta64_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mjconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mtimezone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msessionLocalTimeZone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_jconf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"JavaObject\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Accessor for the JVM SQL-specific configurations\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msessionState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SparkSession\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     format(target_id, \".\", name, value))\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 format(target_id, \".\", name))\n",
            "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o36.sessionState"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the shapes of our RDDs ensures we got this step right. Everything looks good! Let’s move on to fitting the models.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQKJDOGO6hlF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpaf8RMIcP4a"
      },
      "source": [
        "## [OLD] **Model preparation**\n",
        "\n",
        "Prepara i dati: Assicurati che il tuo dataset sia in un formato adatto per l'addestramento del modello. Dovresti avere una colonna di etichette di output (variabile di risposta) e le features (variabili indipendenti) in colonne separate.\n",
        "\n",
        "Crea un VectorAssembler: Un VectorAssembler è utilizzato per combinare le features in una singola colonna vettoriale. Questo passaggio è necessario poiché PySpark richiede che le features siano in un unico vettore per l'addestramento del modello Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agk8Cum2OdQz"
      },
      "outputs": [],
      "source": [
        "# load dataset into pyspark dataset objects\n",
        "df = spark.read.load(GDRIVE_DATASET,\n",
        "                         format=\"csv\",\n",
        "                         sep=\",\",\n",
        "                         inferSchema=\"true\",\n",
        "                         header=\"true\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5-oVeurnfGf"
      },
      "outputs": [],
      "source": [
        "# def model_preparation(dataset):\n",
        "#   from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "#   assembler = VectorAssembler(\n",
        "#       inputCols=[\"close\"],\n",
        "#       outputCol=\"features\"\n",
        "#   )\n",
        "\n",
        "#   dataset = assembler.transform(dataset)\n",
        "\n",
        "#   from pyspark.sql.functions import date_format, to_timestamp\n",
        "\n",
        "#   # transform date column into string\n",
        "#   dataset = dataset.withColumn(\"date_str\", date_format(to_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
        "\n",
        "#   # encode the date to a column of label indicies\n",
        "#   from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "#   label_stringIdx = StringIndexer(inputCol = 'date_str', outputCol = 'labelIndex')\n",
        "#   dataset = label_stringIdx.fit(dataset).transform(dataset)\n",
        "\n",
        "#   # divide the dataset into train set and test set\n",
        "#   from pyspark.sql.functions import percent_rank\n",
        "#   from pyspark.sql import Window\n",
        "\n",
        "#   dataset = dataset.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"date_str\")))\n",
        "#   train = dataset.where(\"rank <= .8\")\n",
        "#   test = dataset.where(\"rank > .8\")\n",
        "\n",
        "#   return train.drop(\"rank\", \"date_str\"), test.drop(\"rank\", \"date_str\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnqzCWd0uETz"
      },
      "outputs": [],
      "source": [
        "# def model_preparation(dataset):\n",
        "#   # Preprocessing: StringIndexer for categorical labels\n",
        "#   stringIndexer  = StringIndexer(inputCol=\"date\", outputCol=\"label\")\n",
        "\n",
        "#   # Define the feature and label columns & Assemble the feature vector\n",
        "#   assembler = VectorAssembler(inputCols=\"close\", outputCol=\"features\")\n",
        "\n",
        "#   return train.drop(\"rank\", \"date_str\"), test.drop(\"rank\", \"date_str\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_preparation(dataset):\n",
        "  from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "  assembler = VectorAssembler(inputCols=['close', 'volume_usd'], outputCol='features')\n",
        "  dataset = assembler.transform(dataset)\n",
        "  dataset = dataset.select('features', 'close')\n",
        "\n",
        "  print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(dataset.count(), len(dataset.columns)))\n",
        "  dataset.printSchema()\n",
        "  dataset.show(5)\n",
        "\n",
        "  # # transform date column into string\n",
        "  # dataset = dataset.withColumn(\"date_str\", date_format(to_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
        "\n",
        "  # # encode the date to a column of label indicies\n",
        "  # from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "  # label_stringIdx = StringIndexer(inputCol = 'date_str', outputCol = 'labelIndex')\n",
        "  # dataset = label_stringIdx.fit(dataset).transform(dataset)\n",
        "\n",
        "  # # divide the dataset into train set and test set\n",
        "  # from pyspark.sql.functions import percent_rank\n",
        "  # from pyspark.sql import Window\n",
        "\n",
        "  # dataset = dataset.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"date_str\")))\n",
        "  # train = dataset.where(\"rank <= .8\")\n",
        "  # test = dataset.where(\"rank > .8\")\n",
        "\n",
        "  # return train.drop(\"rank\", \"date_str\"), test.drop(\"rank\", \"date_str\")"
      ],
      "metadata": {
        "id": "cz9-LCWgMBsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe1u7N0RNTc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "e6258dd6-ebb9-4855-cc0e-246ae2784694"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f8f41010ae46>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train_df, test_df = model_preparation(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_preparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-4f3a137d2f4f>\u001b[0m in \u001b[0;36mmodel_preparation\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0massembler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volume_usd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: Data type timestamp of column date is not supported."
          ]
        }
      ],
      "source": [
        "# train_df, test_df = model_preparation(df)\n",
        "model_preparation(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnOQAwSikMLi"
      },
      "outputs": [],
      "source": [
        "if SLOW_OPERATION:\n",
        "  print(\"The shape of the train dataset is {:d} rows by {:d} columns\".format(train_df.count(), len(train_df.columns)))\n",
        "  train_df.show(5)\n",
        "  print(\"The shape of the test dataset is {:d} rows by {:d} columns\".format(test_df.count(), len(test_df.columns)))\n",
        "  test_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJPBT9vs_zRZ"
      },
      "outputs": [],
      "source": [
        "def compute_daily_df(dataset):\n",
        "  dataset = dataset.drop(\"features\", \"labelIndex\")\n",
        "\n",
        "  dataset = dataset.withColumn(\"date\", date_format(dataset.date, \"yyyy-MM-dd\")).groupBy(\"date\").agg(\n",
        "      avg(\"close\").alias(\"close\")\n",
        "  ).sort(\"date\")\n",
        "\n",
        "  dataset = dataset.withColumn(\"close\", round(dataset[\"close\"], 2))\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGlxw9wPW77V"
      },
      "outputs": [],
      "source": [
        "def show_daily_train_test(train, test):\n",
        "  daily_train_pandas = compute_daily_df(train).toPandas()\n",
        "  daily_test_pandas = compute_daily_df(test).toPandas()\n",
        "\n",
        "  trace1 = go.Scatter(\n",
        "      x = daily_train_pandas['date'],\n",
        "      y = daily_train_pandas['close'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = 'Train set'\n",
        "  )\n",
        "\n",
        "  trace2 = go.Scatter(\n",
        "      x = daily_test_pandas['date'],\n",
        "      y = daily_test_pandas['close'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = 'Test set'\n",
        "  )\n",
        "\n",
        "  layout = dict(\n",
        "      title='Train and Test set with the Slider ',\n",
        "      xaxis=dict(\n",
        "          rangeselector=dict(\n",
        "              buttons=list([\n",
        "                  #change the count to desired amount of months.\n",
        "                  dict(count=1,\n",
        "                      label='1m',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(count=6,\n",
        "                      label='6m',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(count=12,\n",
        "                      label='1y',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(count=36,\n",
        "                      label='3y',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(step='all')\n",
        "              ])\n",
        "          ),\n",
        "          rangeslider=dict(\n",
        "              visible = True\n",
        "          ),\n",
        "          type='date'\n",
        "      )\n",
        "  )\n",
        "\n",
        "  data = [trace1,trace2]\n",
        "  fig = dict(data=data, layout=layout)\n",
        "  iplot(fig, filename = \"Train and Test set  with Rangeslider\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "5uuZJSHkRY12",
        "outputId": "b32cf28c-5525-4a23-fd6e-5994342f119b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"b8b2c5bc-ca49-4666-aebb-ad7e0bf21a0e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b8b2c5bc-ca49-4666-aebb-ad7e0bf21a0e\")) {                    Plotly.newPlot(                        \"b8b2c5bc-ca49-4666-aebb-ad7e0bf21a0e\",                        [{\"mode\":\"lines\",\"name\":\"Train set\",\"x\":[\"2021-07-20\",\"2021-07-21\",\"2021-07-22\",\"2021-07-23\",\"2021-07-24\",\"2021-07-25\",\"2021-07-26\",\"2021-07-27\",\"2021-07-28\",\"2021-07-29\",\"2021-07-30\",\"2021-07-31\",\"2021-08-01\",\"2021-08-02\",\"2021-08-03\",\"2021-08-04\",\"2021-08-05\",\"2021-08-06\",\"2021-08-07\",\"2021-08-08\",\"2021-08-09\",\"2021-08-10\",\"2021-08-11\",\"2021-08-12\",\"2021-08-13\",\"2021-08-14\",\"2021-08-15\",\"2021-08-16\",\"2021-08-17\",\"2021-08-18\",\"2021-08-19\",\"2021-08-20\",\"2021-08-21\",\"2021-08-22\",\"2021-08-23\",\"2021-08-24\",\"2021-08-25\",\"2021-08-26\",\"2021-08-27\",\"2021-08-28\",\"2021-08-29\",\"2021-08-30\",\"2021-08-31\",\"2021-09-01\",\"2021-09-02\",\"2021-09-03\",\"2021-09-04\",\"2021-09-05\",\"2021-09-06\",\"2021-09-07\",\"2021-09-08\",\"2021-09-09\",\"2021-09-10\",\"2021-09-11\",\"2021-09-12\",\"2021-09-13\",\"2021-09-14\",\"2021-09-15\",\"2021-09-16\",\"2021-09-17\",\"2021-09-18\",\"2021-09-19\",\"2021-09-20\",\"2021-09-21\",\"2021-09-22\",\"2021-09-23\",\"2021-09-24\",\"2021-09-25\",\"2021-09-26\",\"2021-09-27\",\"2021-09-28\",\"2021-09-29\",\"2021-09-30\",\"2021-10-01\",\"2021-10-02\",\"2021-10-03\",\"2021-10-04\",\"2021-10-05\",\"2021-10-06\",\"2021-10-07\",\"2021-10-08\",\"2021-10-09\",\"2021-10-10\",\"2021-10-11\",\"2021-10-12\",\"2021-10-13\",\"2021-10-14\",\"2021-10-15\",\"2021-10-16\",\"2021-10-17\",\"2021-10-18\",\"2021-10-19\",\"2021-10-20\",\"2021-10-21\",\"2021-10-22\",\"2021-10-23\",\"2021-10-24\",\"2021-10-25\",\"2021-10-26\",\"2021-10-27\",\"2021-10-28\",\"2021-10-29\",\"2021-10-30\",\"2021-10-31\",\"2021-11-01\",\"2021-11-02\",\"2021-11-03\",\"2021-11-04\",\"2021-11-05\",\"2021-11-06\",\"2021-11-07\",\"2021-11-08\",\"2021-11-09\",\"2021-11-10\",\"2021-11-11\",\"2021-11-12\",\"2021-11-13\",\"2021-11-14\",\"2021-11-15\",\"2021-11-16\",\"2021-11-17\",\"2021-11-18\",\"2021-11-19\",\"2021-11-20\",\"2021-11-21\",\"2021-11-22\",\"2021-11-23\",\"2021-11-24\",\"2021-11-25\",\"2021-11-26\",\"2021-11-27\",\"2021-11-28\",\"2021-11-29\",\"2021-11-30\",\"2021-12-01\",\"2021-12-02\",\"2021-12-03\",\"2021-12-04\",\"2021-12-05\",\"2021-12-06\",\"2021-12-07\",\"2021-12-08\",\"2021-12-09\",\"2021-12-10\",\"2021-12-11\",\"2021-12-12\",\"2021-12-13\",\"2021-12-14\",\"2021-12-15\",\"2021-12-16\",\"2021-12-17\",\"2021-12-18\",\"2021-12-19\",\"2021-12-20\",\"2021-12-21\",\"2021-12-22\",\"2021-12-23\",\"2021-12-24\",\"2021-12-25\",\"2021-12-26\",\"2021-12-27\",\"2021-12-28\",\"2021-12-29\",\"2021-12-30\",\"2021-12-31\",\"2022-01-01\",\"2022-01-02\",\"2022-01-03\",\"2022-01-04\",\"2022-01-05\",\"2022-01-06\",\"2022-01-07\",\"2022-01-08\",\"2022-01-09\",\"2022-01-10\",\"2022-01-11\",\"2022-01-12\",\"2022-01-13\",\"2022-01-14\",\"2022-01-15\",\"2022-01-16\",\"2022-01-17\",\"2022-01-18\",\"2022-01-19\",\"2022-01-20\",\"2022-01-21\",\"2022-01-22\",\"2022-01-23\",\"2022-01-24\",\"2022-01-25\",\"2022-01-26\",\"2022-01-27\",\"2022-01-28\",\"2022-01-29\",\"2022-01-30\",\"2022-01-31\",\"2022-02-01\",\"2022-02-02\",\"2022-02-03\",\"2022-02-04\",\"2022-02-05\",\"2022-02-06\",\"2022-02-07\",\"2022-02-08\",\"2022-02-09\",\"2022-02-10\",\"2022-02-11\",\"2022-02-12\",\"2022-02-13\",\"2022-02-14\",\"2022-02-15\",\"2022-02-16\",\"2022-02-17\",\"2022-02-18\",\"2022-02-19\",\"2022-02-20\",\"2022-02-21\",\"2022-02-22\",\"2022-02-23\",\"2022-02-24\",\"2022-02-25\",\"2022-02-26\",\"2022-02-27\",\"2022-02-28\",\"2022-03-01\",\"2022-03-02\",\"2022-03-03\",\"2022-03-04\",\"2022-03-05\",\"2022-03-06\",\"2022-03-07\",\"2022-03-08\",\"2022-03-09\",\"2022-03-10\",\"2022-03-11\",\"2022-03-12\",\"2022-03-13\",\"2022-03-14\",\"2022-03-15\",\"2022-03-16\",\"2022-03-17\",\"2022-03-18\",\"2022-03-19\",\"2022-03-20\",\"2022-03-21\",\"2022-03-22\",\"2022-03-23\",\"2022-03-24\",\"2022-03-25\",\"2022-03-26\",\"2022-03-27\",\"2022-03-28\",\"2022-03-29\",\"2022-03-30\",\"2022-03-31\",\"2022-04-01\",\"2022-04-02\",\"2022-04-03\",\"2022-04-04\",\"2022-04-05\",\"2022-04-06\",\"2022-04-07\",\"2022-04-08\",\"2022-04-09\",\"2022-04-10\",\"2022-04-11\",\"2022-04-12\",\"2022-04-13\",\"2022-04-14\",\"2022-04-15\",\"2022-04-16\",\"2022-04-17\",\"2022-04-18\",\"2022-04-19\",\"2022-04-20\",\"2022-04-21\",\"2022-04-22\",\"2022-04-23\",\"2022-04-24\",\"2022-04-25\",\"2022-04-26\",\"2022-04-27\",\"2022-04-28\",\"2022-04-29\",\"2022-04-30\",\"2022-05-01\",\"2022-05-02\",\"2022-05-03\",\"2022-05-04\",\"2022-05-05\",\"2022-05-06\",\"2022-05-07\",\"2022-05-08\",\"2022-05-09\",\"2022-05-10\",\"2022-05-11\",\"2022-05-12\",\"2022-05-13\",\"2022-05-14\",\"2022-05-15\",\"2022-05-16\",\"2022-05-17\",\"2022-05-18\",\"2022-05-19\",\"2022-05-20\",\"2022-05-21\",\"2022-05-22\",\"2022-05-23\",\"2022-05-24\",\"2022-05-25\",\"2022-05-26\",\"2022-05-27\",\"2022-05-28\",\"2022-05-29\",\"2022-05-30\",\"2022-05-31\",\"2022-06-01\",\"2022-06-02\",\"2022-06-03\",\"2022-06-04\",\"2022-06-05\",\"2022-06-06\",\"2022-06-07\",\"2022-06-08\",\"2022-06-09\",\"2022-06-10\",\"2022-06-11\",\"2022-06-12\",\"2022-06-13\",\"2022-06-14\",\"2022-06-15\",\"2022-06-16\",\"2022-06-17\",\"2022-06-18\",\"2022-06-19\",\"2022-06-20\",\"2022-06-21\",\"2022-06-22\",\"2022-06-23\",\"2022-06-24\",\"2022-06-25\",\"2022-06-26\",\"2022-06-27\",\"2022-06-28\",\"2022-06-29\",\"2022-06-30\",\"2022-07-01\",\"2022-07-02\",\"2022-07-03\",\"2022-07-04\",\"2022-07-05\",\"2022-07-06\",\"2022-07-07\",\"2022-07-08\",\"2022-07-09\",\"2022-07-10\",\"2022-07-11\",\"2022-07-12\",\"2022-07-13\",\"2022-07-14\",\"2022-07-15\",\"2022-07-16\",\"2022-07-17\",\"2022-07-18\",\"2022-07-19\",\"2022-07-20\",\"2022-07-21\",\"2022-07-22\",\"2022-07-23\",\"2022-07-24\",\"2022-07-25\",\"2022-07-26\",\"2022-07-27\",\"2022-07-28\",\"2022-07-29\",\"2022-07-30\",\"2022-07-31\",\"2022-08-01\",\"2022-08-02\",\"2022-08-03\",\"2022-08-04\",\"2022-08-05\",\"2022-08-06\",\"2022-08-07\",\"2022-08-08\",\"2022-08-09\",\"2022-08-10\",\"2022-08-11\",\"2022-08-12\",\"2022-08-13\",\"2022-08-14\",\"2022-08-15\",\"2022-08-16\",\"2022-08-17\",\"2022-08-18\",\"2022-08-19\",\"2022-08-20\",\"2022-08-21\",\"2022-08-22\",\"2022-08-23\",\"2022-08-24\",\"2022-08-25\",\"2022-08-26\",\"2022-08-27\",\"2022-08-28\",\"2022-08-29\",\"2022-08-30\",\"2022-08-31\",\"2022-09-01\",\"2022-09-02\",\"2022-09-03\",\"2022-09-04\",\"2022-09-05\",\"2022-09-06\",\"2022-09-07\",\"2022-09-08\",\"2022-09-09\",\"2022-09-10\",\"2022-09-11\",\"2022-09-12\",\"2022-09-13\",\"2022-09-14\",\"2022-09-15\",\"2022-09-16\",\"2022-09-17\",\"2022-09-18\",\"2022-09-19\",\"2022-09-20\",\"2022-09-21\",\"2022-09-22\",\"2022-09-23\",\"2022-09-24\",\"2022-09-25\",\"2022-09-26\",\"2022-09-27\",\"2022-09-28\",\"2022-09-29\",\"2022-09-30\",\"2022-10-01\",\"2022-10-02\",\"2022-10-03\",\"2022-10-04\",\"2022-10-05\",\"2022-10-06\",\"2022-10-07\",\"2022-10-08\",\"2022-10-09\",\"2022-10-10\",\"2022-10-11\",\"2022-10-12\",\"2022-10-13\",\"2022-10-14\",\"2022-10-15\",\"2022-10-16\",\"2022-10-17\",\"2022-10-18\",\"2022-10-19\",\"2022-10-20\",\"2022-10-21\",\"2022-10-22\",\"2022-10-23\",\"2022-10-24\",\"2022-10-25\",\"2022-10-26\",\"2022-10-27\"],\"y\":[29838.64,31197.04,32136.08,32490.99,33878.84,34392.47,38319.71,37694.8,39876.01,39865.45,39639.55,41642.75,41485.27,39603.41,38456.1,38710.22,39430.55,41364.87,43570.44,44356.25,44904.37,45600.57,46089.47,44932.27,46213.89,47123.02,46445.75,46926.01,45968.12,45144.58,45219.35,47778.63,49050.68,48905.33,49891.19,48911.52,48266.8,47351.78,47745.74,48903.91,48669.46,48088.32,47304.62,47686.21,49667.93,49911.82,50077.88,50361.34,51791.66,49980.16,46299.65,46423.54,45924.74,45373.22,45640.74,44803.94,46052.31,47591.15,47900.63,47581.82,48240.84,47734.03,44627.95,42445.11,42571.32,44100.76,43135.29,42596.49,42801.91,43524.05,41936.39,41826.2,43264.71,46070.2,47847.31,48030.89,48164.79,50082.64,52931.75,54365.37,54462.88,54745.01,55167.29,56704.94,56630.81,56052.11,57646.51,59889.19,61279.12,60848.77,61797.75,62738.99,64968.28,64330.5,62181.76,61090.78,60710.68,62613.54,62306.75,59513.09,60255.34,61584.52,61630.13,61118.1,61292.51,62550.8,62854.98,61857.13,61532.35,60993.45,62137.66,65806.22,67535.69,66868.43,64930.06,64174.27,64055.81,64485.26,65103.76,60814.92,59888.97,59013.83,57235.21,58720.63,59173.15,57375.16,56923.34,56765.29,58279.07,55685.27,54688.26,54630.78,57611.78,57365.41,57406.45,56693.4,55875.24,49050.38,49151.17,48857.99,51023.24,50323.59,49079.34,48536.56,48484.57,49593.7,48209.02,47211.31,48137.47,48595.02,47084.64,46636.5,47202.69,46437.34,48426.13,48994.49,49103.23,51064.06,50857.59,50174.04,51085.36,48867.7,47586.06,47104.89,47291.88,47124.09,47249.72,46824.12,46431.99,45900.98,43094.88,41997.98,41712.95,41909.55,41617.78,42215.15,43205.99,43437.44,42765.27,43153.47,43117.45,42548.28,41943.8,41918.99,42212.58,38664.52,35510.07,35437.23,35110.01,36519.57,37516.36,36365.29,37060.28,37840.07,37967.19,37573.53,38577.45,38057.23,36819.07,38680.69,41545.03,41620.71,43132.21,43884.91,43954.98,44373.31,43190.01,42347.3,42353.22,42246.35,43903.99,44014.42,42653.11,40417.39,40081.45,38759.07,38503.95,37420.67,38227.58,36138.0,38845.95,39231.93,38714.02,39414.77,43657.34,44071.38,43122.09,40942.15,39166.06,39022.76,38260.05,38641.25,41548.17,39631.12,38969.78,39113.07,38900.16,38736.13,39018.48,40242.86,40912.22,40973.12,41873.32,41647.94,41114.29,42469.04,42265.28,43356.46,44297.55,44412.85,44967.74,47323.73,47570.21,47251.58,46675.27,45549.38,46460.51,46338.69,46052.78,46345.84,44619.38,43458.58,43301.72,42466.72,42760.33,41215.31,39942.03,40475.36,40696.22,40234.88,40398.83,40310.32,39671.39,41057.47,41466.66,41702.84,40140.05,39683.75,39639.0,39234.93,39667.69,38819.09,39617.55,39082.34,38501.29,38066.64,38671.96,38243.33,38816.11,38412.83,36140.47,35850.46,34540.84,32653.97,31353.3,30550.42,28347.79,30123.46,29355.41,30090.0,29946.72,30253.5,29572.75,29533.42,29780.37,29313.92,29771.11,30065.9,29288.85,29728.37,29421.86,28867.0,28867.36,29122.62,30598.24,31695.61,31042.64,30028.98,29966.08,29681.88,29800.02,31235.01,29999.02,30443.36,30232.83,29631.84,28841.66,27606.65,24211.54,22169.2,21342.85,21416.76,20680.3,19320.96,19278.61,20292.1,20993.84,20297.96,20524.74,21087.45,21258.46,21360.97,21041.55,20689.67,20130.76,19334.12,19524.17,19218.58,19148.98,19504.72,19987.03,20173.57,20779.46,21756.28,21614.9,21128.95,20464.74,19748.33,19606.51,20174.15,20783.77,20871.07,21218.85,21830.37,22528.35,23571.88,22937.54,23142.58,22514.75,22650.25,21949.79,21032.38,21659.88,23318.41,23888.81,24038.39,23732.98,23228.71,22971.53,23178.48,22852.67,23074.66,23192.15,23085.26,23796.39,23440.38,23413.83,24378.72,23991.96,24539.16,24511.32,24268.57,23972.06,23700.08,23418.61,21837.74,21176.16,21379.07,21265.51,21394.05,21473.08,21601.53,21163.17,20123.34,19995.7,19980.86,20140.76,20205.28,19971.25,20090.0,19844.05,19805.93,19791.58,19600.89,18906.25,19258.78,20736.35,21392.61,21611.47,21738.82,21494.56,20223.75,19987.64,19707.83,19950.68,19860.32,19008.53,19180.22,19007.98,18982.22,19056.84,19078.39,18983.04,19016.06,19736.39,19122.76,19396.04,19527.24,19329.7,19230.83,19318.27,19942.85,20127.09,20152.05,19768.27,19493.7,19446.85,19327.44,19068.7,19118.9,19031.5,19517.67,19144.53,19168.75,19401.43,19476.15,19215.81,19120.83,19066.87,19178.85,19268.59,19356.26,19599.68,20547.97,20760.0],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test set\",\"x\":[\"2022-10-27\",\"2022-10-28\",\"2022-10-29\",\"2022-10-30\",\"2022-10-31\",\"2022-11-01\",\"2022-11-02\",\"2022-11-03\",\"2022-11-04\",\"2022-11-05\",\"2022-11-06\",\"2022-11-07\",\"2022-11-08\",\"2022-11-09\",\"2022-11-10\",\"2022-11-11\",\"2022-11-12\",\"2022-11-13\",\"2022-11-14\",\"2022-11-15\",\"2022-11-16\",\"2022-11-17\",\"2022-11-18\",\"2022-11-19\",\"2022-11-20\",\"2022-11-21\",\"2022-11-22\",\"2022-11-23\",\"2022-11-24\",\"2022-11-25\",\"2022-11-26\",\"2022-11-27\",\"2022-11-28\",\"2022-11-29\",\"2022-11-30\",\"2022-12-01\",\"2022-12-02\",\"2022-12-03\",\"2022-12-04\",\"2022-12-05\",\"2022-12-06\",\"2022-12-07\",\"2022-12-08\",\"2022-12-09\",\"2022-12-10\",\"2022-12-11\",\"2022-12-12\",\"2022-12-13\",\"2022-12-14\",\"2022-12-15\",\"2022-12-16\",\"2022-12-17\",\"2022-12-18\",\"2022-12-19\",\"2022-12-20\",\"2022-12-21\",\"2022-12-22\",\"2022-12-23\",\"2022-12-24\",\"2022-12-25\",\"2022-12-26\",\"2022-12-27\",\"2022-12-28\",\"2022-12-29\",\"2022-12-30\",\"2022-12-31\",\"2023-01-01\",\"2023-01-02\",\"2023-01-03\",\"2023-01-04\",\"2023-01-05\",\"2023-01-06\",\"2023-01-07\",\"2023-01-08\",\"2023-01-09\",\"2023-01-10\",\"2023-01-11\",\"2023-01-12\",\"2023-01-13\",\"2023-01-14\",\"2023-01-15\",\"2023-01-16\",\"2023-01-17\",\"2023-01-18\",\"2023-01-19\",\"2023-01-20\",\"2023-01-21\",\"2023-01-22\",\"2023-01-23\",\"2023-01-24\",\"2023-01-25\",\"2023-01-26\",\"2023-01-27\",\"2023-01-28\",\"2023-01-29\",\"2023-01-30\",\"2023-01-31\",\"2023-02-01\",\"2023-02-02\",\"2023-02-03\",\"2023-02-04\",\"2023-02-05\",\"2023-02-06\",\"2023-02-07\",\"2023-02-08\",\"2023-02-09\",\"2023-02-10\",\"2023-02-11\",\"2023-02-12\",\"2023-02-13\",\"2023-02-14\",\"2023-02-15\",\"2023-02-16\",\"2023-02-17\",\"2023-02-18\",\"2023-02-19\",\"2023-02-20\",\"2023-02-21\"],\"y\":[20603.43,20392.25,20787.7,20726.03,20512.36,20504.45,20409.45,20256.72,20708.14,21339.39,21219.22,20768.54,19557.16,17515.86,16919.39,17065.22,16802.26,16621.84,16439.56,16817.85,16676.88,16585.73,16720.62,16626.25,16564.62,16012.29,15928.93,16455.99,16598.11,16484.41,16560.23,16537.36,16205.64,16412.55,16900.85,17061.91,16969.84,16987.93,17024.95,17175.73,16999.57,16883.95,16856.49,17187.47,17171.33,17160.93,16999.92,17475.29,17873.02,17582.44,17130.62,16710.8,16742.37,16677.8,16798.95,16833.92,16778.56,16829.93,16831.25,16821.63,16848.84,16796.93,16627.39,16581.39,16541.52,16554.81,16550.33,16685.96,16683.8,16823.43,16828.14,16823.71,16937.92,16947.86,17240.08,17291.07,17459.34,18343.65,19078.71,20824.55,20786.15,21043.86,21197.85,21123.28,20851.99,21309.11,22891.33,22806.87,22833.16,22966.72,22709.82,23072.92,23004.01,23030.43,23445.49,23276.71,22965.65,23168.39,23822.32,23479.33,23394.75,23199.43,22908.52,22986.96,23100.07,22535.75,21775.53,21704.36,21865.34,21692.08,21911.96,22710.24,24614.27,24020.26,24620.87,24644.68,24662.87,24819.28],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Train and Test set with the Slider \"},\"xaxis\":{\"rangeselector\":{\"buttons\":[{\"count\":1,\"label\":\"1m\",\"step\":\"month\",\"stepmode\":\"backward\"},{\"count\":6,\"label\":\"6m\",\"step\":\"month\",\"stepmode\":\"backward\"},{\"count\":12,\"label\":\"1y\",\"step\":\"month\",\"stepmode\":\"backward\"},{\"count\":36,\"label\":\"3y\",\"step\":\"month\",\"stepmode\":\"backward\"},{\"step\":\"all\"}]},\"rangeslider\":{\"visible\":true},\"type\":\"date\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b8b2c5bc-ca49-4666-aebb-ad7e0bf21a0e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_daily_train_test(train_df, test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output"
      ],
      "metadata": {
        "id": "HHoQJdCYGygi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-owrgEPHQ7K"
      },
      "source": [
        "Saving the final train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miO1DZVW1D9i"
      },
      "outputs": [],
      "source": [
        "def output(dataset, typology):\n",
        "  from pyspark.sql.functions import date_format, to_timestamp, col\n",
        "\n",
        "  # transform date column into string\n",
        "  dataset = dataset.withColumn(\"date\", to_timestamp(col(\"date\"), \"yyyy-MM-dd HH:mm:ss\").cast(\"string\"))\n",
        "\n",
        "  # definition of Vector to String conversion function\n",
        "  vector_to_string = udf(lambda vector: str(vector), StringType())\n",
        "\n",
        "  # applying the function to the features column\n",
        "  dataset = dataset.withColumn(\"features\", vector_to_string(dataset[\"features\"]))\n",
        "\n",
        "  # save the dataset in CSV format\n",
        "  dataset.repartition(1).write.csv(GDRIVE_DATASET_TEMP_DIR, header=True, mode='overwrite')\n",
        "\n",
        "  import os\n",
        "  import glob\n",
        "  import time\n",
        "\n",
        "  while True:\n",
        "      csv_files = glob.glob(os.path.join(GDRIVE_DATASET_TEMP_DIR, \"part*.csv\"))\n",
        "      if len(csv_files) > 0:\n",
        "          # .csv file found!\n",
        "          file_path = csv_files[0]\n",
        "          break\n",
        "      else:\n",
        "          print(\".csv file not found. I'll try again after 1 second...\")\n",
        "          time.sleep(1)\n",
        "\n",
        "  print(\".csv file found:\", file_path)\n",
        "\n",
        "  new_file_path = GDRIVE_DATASET_OUTPUT_DIR + \"/\" + GDRIVE_DATASET_NAME + \"_\" + typology + \".csv\"\n",
        "\n",
        "  import shutil\n",
        "\n",
        "  # rename and move the file\n",
        "  shutil.move(file_path, new_file_path)\n",
        "\n",
        "  print(\"File renamed and moved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8mHxapmSAC7",
        "outputId": "e2e9614f-a756-4ccd-bec8-8d9117aab52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".csv file found: /content/drive/MyDrive/Computer_Science/BDC/project/datasets/temp/part-00000-c85b88ff-d0a5-44b3-a848-1f640d5df9ec-c000.csv\n",
            "File renamed and moved successfully!\n",
            ".csv file found: /content/drive/MyDrive/Computer_Science/BDC/project/datasets/temp/part-00000-2f02edff-d40b-49fd-a2f8-883e4d0b3fd7-c000.csv\n",
            "File renamed and moved successfully!\n"
          ]
        }
      ],
      "source": [
        "output(train_df, \"train\")\n",
        "output(test_df, \"test\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "303fa613b6f3e1efefe7bb28036e305e1021fa6bdb083a5f9fd57f9d9bbad8eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}