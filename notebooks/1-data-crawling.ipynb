{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fiscal-income",
      "metadata": {
        "id": "fiscal-income"
      },
      "source": [
        "# **Bitcoin price prediction - Data crawling**\n",
        "## Big Data Computing final project - A.Y. 2022 - 2023\n",
        "Prof. Gabriele Tolomei\n",
        "\n",
        "MSc in Computer Science\n",
        "\n",
        "La Sapienza, University of Rome\n",
        "\n",
        "### Author: Corsi Danilo (1742375) - corsi.1742375@studenti.uniroma1.it\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Description: crawling data on bitcoin's blochckain by querying blockchain.com."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755ac6e8",
      "metadata": {
        "id": "755ac6e8"
      },
      "source": [
        "# Global constants, dependencies, libraries and tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831b87c7",
      "metadata": {
        "id": "831b87c7"
      },
      "outputs": [],
      "source": [
        "# Main constants\n",
        "LOCAL_RUNNING = False\n",
        "ROOT_DIR = \"D:/Documents/Repository/BDC/project\" if LOCAL_RUNNING else \"/content/drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce41ce4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce41ce4d",
        "outputId": "13bda7ac-83c1-43e3-d928-fd806cf5f793"
      },
      "outputs": [],
      "source": [
        "if not LOCAL_RUNNING:\n",
        "    # Point Colaboratory to Google Drive\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Define GDrive paths\n",
        "    drive.mount(ROOT_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zYUO2FsHhBRS",
      "metadata": {
        "id": "zYUO2FsHhBRS"
      },
      "outputs": [],
      "source": [
        "# Set main dir\n",
        "MAIN_DIR = ROOT_DIR + \"\" if LOCAL_RUNNING else ROOT_DIR + \"/MyDrive/BDC/project\"\n",
        "\n",
        "# Datasets dir\n",
        "DATASET_RAW_DIR = MAIN_DIR + \"/datasets/raw\"\n",
        "\n",
        "# Datasets name\n",
        "DATASET_NAME = \"bitcoin_blockchain_data_15min\"\n",
        "\n",
        "# Datasets path\n",
        "DATASET_RAW = DATASET_RAW_DIR + \"/\" + DATASET_NAME + \".parquet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "forbidden-kuwait",
      "metadata": {
        "id": "forbidden-kuwait"
      },
      "outputs": [],
      "source": [
        "# Useful imports\n",
        "import pandas as pd\n",
        "import functools\n",
        "import plotly.io as pio\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "if not LOCAL_RUNNING: from google.colab import drive\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "if LOCAL_RUNNING: pio.renderers.default='notebook' # To correctly export the notebook in html format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a87cfb",
      "metadata": {
        "id": "96a87cfb"
      },
      "source": [
        "# Metrics and parameters\n",
        "I chose to collect data on the Bitcoin blockchain using the API of the website Blockchain.org, the most relevant information was retrieved from the last four years to the present day (a period for which there were moments of high volatility but also a lot of price lateralization). The procedure has been made as automatic as possible so that the same periods are considered each time the entire procedure is run.\n",
        "\n",
        "The features taken under consideration were divided into several categories:\n",
        "\n",
        "**Currency Statistics**\n",
        "- **ohlcv:** stands for “Open, High, Low, Close and Volume”and it's a list of the five types of data that are most common in financial analysis regarding price.\n",
        "- **market-price:** the average USD market price across major bitcoin exchanges.\n",
        "- **trade-volume:** the total USD value of trading volume on major bitcoin exchanges.\n",
        "- **total-bitcoins:** the total number of mined bitcoin that are currently circulating on the network.\n",
        "- **market-cap:** the total USD value of bitcoin in circulation.\n",
        "\n",
        "**Block Details**\n",
        "\n",
        "- **blocks-size:** the total size of the blockchain minus database indexes in megabytes.\n",
        "- **avg-block-size:** the average block size over the past 24 hours in megabytes.\n",
        "- **n-transactions-total:** the total number of transactions on the blockchain.\n",
        "- **n-transactions-per-block:** the average number of transactions per block over the past 24 hours.\n",
        "\n",
        "**Mining Information**\n",
        "\n",
        "- **hash-rate:** the estimated number of terahashes per second the bitcoin network is performing in the last 24 hours.\n",
        "- **difficulty:** a relative measure of how difficult it is to mine a new block for the blockchain.\n",
        "- **miners-revenue:** total value of coinbase block rewards and transaction fees paid to miners.\n",
        "- **transaction-fees-usd:** the total USD value of all transaction fees paid to miners. This does not include coinbase block rewards.\n",
        "\n",
        "**Network Activity**\n",
        "\n",
        "- **n-unique-addresses:** the total number of unique addresses used on the blockchain.\n",
        "- **n-transactions:** the total number of confirmed transactions per day.\n",
        "- **estimated-transaction-volume-usd:** the total estimated value in USD of transactions on the blockchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manual-spring",
      "metadata": {
        "id": "manual-spring"
      },
      "outputs": [],
      "source": [
        "# Define the parameters\n",
        "timespan = \"4years\" # Duration of the data\n",
        "# Get current date (ending date)\n",
        "end_date = datetime.today()\n",
        "# Get the starting date\n",
        "start_date = (datetime.today() - timedelta(days=365*4))\n",
        "\n",
        "# Metrics considered\n",
        "metrics = [\n",
        "          # Currency Statistics\n",
        "          \"market-price\",\n",
        "          \"trade-volume\",\n",
        "\n",
        "          # Block Details\n",
        "          \"blocks-size\",\n",
        "          \"avg-block-size\",\n",
        "          \"n-transactions-total\",\n",
        "          \"n-transactions-per-block\",\n",
        "\n",
        "          # Mining Information\n",
        "          \"hash-rate\",\n",
        "          \"difficulty\",\n",
        "          \"miners-revenue\",\n",
        "          \"transaction-fees-usd\",\n",
        "\n",
        "          # Network Activity\n",
        "          \"n-unique-addresses\",\n",
        "          \"n-transactions\",\n",
        "          \"estimated-transaction-volume-usd\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ZWQKvjSXM6L",
      "metadata": {
        "id": "1ZWQKvjSXM6L"
      },
      "source": [
        "# Data crawling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R9ASh9qYDlJ9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ASh9qYDlJ9",
        "outputId": "19b0afe6-9e06-4201-fe0e-bd058f14cdf2"
      },
      "outputs": [],
      "source": [
        "# Install ccxt trading library that provides a way to connect and trade with various cryptocurrency exchanges and payment processing services worldwide\n",
        "!pip3 install ccxt\n",
        "import ccxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Rv5G8NMG2QE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rv5G8NMG2QE",
        "outputId": "8bf8e977-cc0a-416e-fbf6-67a17111bdc9"
      },
      "outputs": [],
      "source": [
        "# Create an array of dates in such a way as to contact the API in one-year increments\n",
        "date_array = []\n",
        "\n",
        "# Calculate the number of days between the start and end dates\n",
        "num_days = (end_date - start_date).days\n",
        "\n",
        "# Loop through the dates and add them to the array\n",
        "for i in range(num_days + 1):\n",
        "    current_date = start_date + timedelta(days=i)\n",
        "    if i % 360 == 0:\n",
        "        date_array.append(current_date)\n",
        "\n",
        "# Append end_date\n",
        "date_array.append(end_date)\n",
        "date_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2YUveOpBDSf7",
      "metadata": {
        "id": "2YUveOpBDSf7"
      },
      "outputs": [],
      "source": [
        "def ohlcv_crawler(exchange_to_use, start, end):\n",
        "    exchange = exchange_to_use  # Connect to the exchange exchange\n",
        "    market = 'BTC/USD'  # Bitcoin market\n",
        "    exchange.enableRateLimit = False\n",
        "\n",
        "    # Convert dates to milliseconds\n",
        "    since = exchange.parse8601(start + 'T00:00:00Z')\n",
        "    till = exchange.parse8601(end + 'T00:00:00Z')\n",
        "\n",
        "    # Fetch OHLCV data\n",
        "    ohlcv = exchange.fetch_ohlcv(market, '1d', since, till)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    dataset = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "    dataset['timestamp'] = pd.to_datetime(dataset['timestamp'], unit='ms')\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pVI0WtO_DaXf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pVI0WtO_DaXf",
        "outputId": "a5d6e676-b132-4850-ecf0-514ef3cda34d"
      },
      "outputs": [],
      "source": [
        "# Fetch OHLCV data\n",
        "exchange_to_use = ccxt.binanceus()\n",
        "\n",
        "df0 = pd.DataFrame()\n",
        "j = 1\n",
        "for i in range(3):\n",
        "  df0 = df0.append(ohlcv_crawler(exchange_to_use, date_array[i].strftime('%Y-%m-%d'), date_array[j].strftime('%Y-%m-%d')), ignore_index=True)\n",
        "  time.sleep(5)\n",
        "  j += 1\n",
        "df0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DEliZI1tcNvz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEliZI1tcNvz",
        "outputId": "22064b93-e835-449e-db2c-8b2c42768428"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df0['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rZinNU6mXo5M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rZinNU6mXo5M",
        "outputId": "f4ebaac6-d349-4bbf-a028-1aaedda0cfc7"
      },
      "outputs": [],
      "source": [
        "# Drop the duplicates in column \"timestamp\", keep the last value\n",
        "df0.drop_duplicates(subset=\"timestamp\", keep=\"last\", inplace=True)\n",
        "df0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rzsbWjzIcWcO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzsbWjzIcWcO",
        "outputId": "cc48aab5-fbdb-48f0-bb09-0910e902b64c"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df0['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uh38Ej0SX4JQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Uh38Ej0SX4JQ",
        "outputId": "7376ce82-13a1-4677-9a34-b8e429f4fadf"
      },
      "outputs": [],
      "source": [
        "# Since I cannot get all the data from the same exchange, I will get the remaining data from another\n",
        "last_date = df0['timestamp'].tail(1).values[0]\n",
        "\n",
        "# Compare the last date with our end date\n",
        "if not last_date == end_date:\n",
        "  exchange_to_use = ccxt.kraken()\n",
        "  for i in range(3):\n",
        "    df0 = df0.append(ohlcv_crawler(exchange_to_use, pd.to_datetime(last_date).strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')), ignore_index=True)\n",
        "df0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYlyNX5LcPLz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYlyNX5LcPLz",
        "outputId": "b74f8521-6087-45bb-c5e4-a724bff7e58e"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df0['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zs8IF6SIZqGS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zs8IF6SIZqGS",
        "outputId": "f29a5442-e37c-462a-c8b2-01be4dccbe53"
      },
      "outputs": [],
      "source": [
        "# Drop the duplicates in column \"timestamp\", keep the last value\n",
        "df0.drop_duplicates(subset=\"timestamp\", keep=\"last\", inplace=True)\n",
        "df0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ao4atcjwcT4R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao4atcjwcT4R",
        "outputId": "422f2a62-9bf3-452c-fe05-f1a26276e230"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df0['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "about-sullivan",
      "metadata": {
        "id": "about-sullivan"
      },
      "outputs": [],
      "source": [
        "def blockchain_data_crawler(timespan, metrics, start, end):\n",
        "    # API info\n",
        "    url = f'https://api.blockchain.info/charts/{metrics}?timespan={timespan}&start={start}&format=csv'\n",
        "\n",
        "    # Obtain data\n",
        "    data = pd.read_csv(url, names=['timestamp', metrics])\n",
        "\n",
        "    # Transform \"timestamp\" to datetime type\n",
        "    data['timestamp'] = pd.to_datetime(data[\"timestamp\"])\n",
        "\n",
        "    # Select data up to the end date\n",
        "    data = data[(data['timestamp'] < end)]\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiac-allocation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "cardiac-allocation",
        "outputId": "bcb41964-00bb-439e-9197-c4bce58b0356"
      },
      "outputs": [],
      "source": [
        "# Merge the data\n",
        "merge = functools.partial(pd.merge, on='timestamp')\n",
        "\n",
        "# Gain blockchain data from Blockchain.com API\n",
        "df1 = functools.reduce(merge, [blockchain_data_crawler(timespan, metric, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')) for metric in metrics])\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "material-calvin",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "material-calvin",
        "outputId": "cabb1339-9e98-4889-c562-a06d6503225e"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df1['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "finite-galaxy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "finite-galaxy",
        "outputId": "78aa9e93-8973-41c9-869e-9eda623326d3"
      },
      "outputs": [],
      "source": [
        "# Retrieving market capitalization and total circulating data\n",
        "metrics = [\n",
        "          # Currency Statistics\n",
        "          \"total-bitcoins\",\n",
        "          \"market-cap\",\n",
        "  ]\n",
        "\n",
        "df2 = functools.reduce(merge, [blockchain_data_crawler(timespan, metric, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')) for metric in metrics])\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "particular-shirt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "particular-shirt",
        "outputId": "97cbc3f9-9810-4057-daf0-b6b3282d937f"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df2['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "arbitrary-bulletin",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "arbitrary-bulletin",
        "outputId": "5a3c50a2-e5ac-4781-8e5c-36ef9c3f0598"
      },
      "outputs": [],
      "source": [
        "# Wipe off the timestamp's h:m:s.\n",
        "df2['timestamp'] = pd.to_datetime(df2[\"timestamp\"]).dt.normalize()\n",
        "\n",
        "# Drop the duplicates in column \"timestamp\", keep the last value\n",
        "df2.drop_duplicates(subset=\"timestamp\", keep=\"last\", inplace=True)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "political-application",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "political-application",
        "outputId": "4f78c1b5-bfc3-4229-bd44-a97442b59495"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(df2['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "orange-marriage",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "orange-marriage",
        "outputId": "eeba4560-40c3-4c0f-8b07-a3ff72c96c64"
      },
      "outputs": [],
      "source": [
        "all_data_tmp = pd.merge(df0, df1, how=\"inner\", on='timestamp')\n",
        "all_data = pd.merge(all_data_tmp, df2, how=\"inner\", on='timestamp')\n",
        "all_data = all_data.interpolate(method='ffill')\n",
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "overhead-driving",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "overhead-driving",
        "outputId": "4c39bccb-0747-47bf-f08c-bd1d44c47ec4"
      },
      "outputs": [],
      "source": [
        "# Check nan values\n",
        "all_data[all_data.isnull().T.any()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "historic-british",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "historic-british",
        "outputId": "41927608-e699-4e03-b826-a85a0b56fe60"
      },
      "outputs": [],
      "source": [
        "# Check duplicated rows\n",
        "len(all_data['timestamp'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stainless-actress",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "stainless-actress",
        "outputId": "2a4187eb-3d2f-4548-c3ea-f7f6f5f7a5c7"
      },
      "outputs": [],
      "source": [
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pen7i6OmTxTJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "pen7i6OmTxTJ",
        "outputId": "12af9c73-ab64-4124-99ac-1066307ca320"
      },
      "outputs": [],
      "source": [
        "# Reorder colunmns\n",
        "new_columns = ['timestamp', 'market-price', 'open', 'high', 'low', 'close', 'volume', 'total-bitcoins', 'market-cap'] + [col for col in all_data.columns if col not in ['timestamp', 'market-price', 'open', 'high', 'low', 'close', 'volume', 'total-bitcoins', 'market-cap']]\n",
        "all_data = all_data.reindex(columns=new_columns)\n",
        "all_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IW-8OVAeCEnp",
      "metadata": {
        "id": "IW-8OVAeCEnp"
      },
      "source": [
        "Once I have the daily dataset I will sample it at a frequency of 15 minutes (15T) using the resample method.\n",
        "\n",
        "This means that the data will be organized in 15-minute time-frame, and an interpolation method will be used to fill in any missing data or holes in the dataset by estimating missing values based on the surrounding known values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-halloween",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "hidden-halloween",
        "outputId": "08e288de-7de2-42f9-8883-a0ef0c0a3e26"
      },
      "outputs": [],
      "source": [
        "# Upsampling to 15min by interpolate\n",
        "all_data.set_index('timestamp', inplace=True)\n",
        "all_data_15m = all_data.resample('15T').interpolate()\n",
        "all_data_15m"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QOZBr5VnXXe0",
      "metadata": {
        "id": "QOZBr5VnXXe0"
      },
      "source": [
        "# Saving dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "anYb8uKPU6pZ",
      "metadata": {
        "id": "anYb8uKPU6pZ"
      },
      "outputs": [],
      "source": [
        "# Save the 15m dataset\n",
        "all_data_15m.to_parquet(DATASET_RAW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CCu55fiMgdD4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCu55fiMgdD4",
        "outputId": "2fee714c-2857-41ab-e217-3c6ad7c70171"
      },
      "outputs": [],
      "source": [
        "# Export notebook in html format (remember to save the notebook and change the model name)\n",
        "if LOCAL_RUNNING: \n",
        "    !jupyter nbconvert --to html 1-data-crawling.ipynb --output 1-data-crawling.ipynb --output-dir='./exports'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
