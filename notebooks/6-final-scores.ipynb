{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e452Ydj7chNV"
      },
      "source": [
        "# **Bitcoin price prediction - Final scores**\n",
        "### Big Data Computing final project - A.Y. 2022 - 2023\n",
        "Prof. Gabriele Tolomei\n",
        "\n",
        "MSc in Computer Science\n",
        "\n",
        "La Sapienza, University of Rome\n",
        "\n",
        "### Author: Corsi Danilo (1742375) - corsi.1742375@studenti.uniroma1.it\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Description: testing the final models and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTGTgzEqE3x"
      },
      "source": [
        "# Global constants, dependencies, libraries and tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av93BTCYR815"
      },
      "outputs": [],
      "source": [
        "# Main constants\n",
        "LOCAL_RUNNING = False\n",
        "ROOT_DIR = \"D:/Documents/Repository/BDC/project\" if LOCAL_RUNNING else \"/content/drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZVTH76BiJps",
        "outputId": "9f066e31-16b4-4920-8db4-702af2280445"
      },
      "outputs": [],
      "source": [
        "if not LOCAL_RUNNING:\n",
        "    # Point Colaboratory to Google Drive\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Define GDrive paths\n",
        "    drive.mount(ROOT_DIR, force_remount=True)\n",
        "\n",
        "    # Install Spark and related dependencies\n",
        "    !pip install pyspark\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq\n",
        "\n",
        "    # Install \"kaleido\" engine package to export image\n",
        "    !pip install -U kaleido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBRexBrot8Gg"
      },
      "source": [
        "## Import my utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGWKLtp9t8Gh",
        "outputId": "81f30118-0b69-4c1b-e47f-26ac656e11b7"
      },
      "outputs": [],
      "source": [
        "# Set main dir\n",
        "MAIN_DIR = ROOT_DIR + \"\" if LOCAL_RUNNING else ROOT_DIR + \"/MyDrive/BDC/project\"\n",
        "\n",
        "# Utilities dir\n",
        "UTILITIES_DIR = MAIN_DIR + \"/utilities\"\n",
        "\n",
        "# Import my utilities\n",
        "import sys\n",
        "sys.path.append(UTILITIES_DIR)\n",
        "\n",
        "from imports import *\n",
        "from config import *\n",
        "import final_scores_utilities\n",
        "\n",
        "importlib.reload(final_scores_utilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BphCu7S0OJyE"
      },
      "outputs": [],
      "source": [
        "# Set main dir\n",
        "MAIN_DIR = ROOT_DIR + \"\" if LOCAL_RUNNING else ROOT_DIR + \"/MyDrive/BDC/project\"\n",
        "\n",
        "###################\n",
        "# --- DATASET --- #\n",
        "###################\n",
        "\n",
        "# Datasets dirs\n",
        "DATASET_OUTPUT_DIR = MAIN_DIR + \"/datasets/output\"\n",
        "\n",
        "# Datasets paths\n",
        "DATASET_TEST = DATASET_OUTPUT_DIR + \"/\" + DATASET_TEST_NAME + \".parquet\"\n",
        "\n",
        "####################\n",
        "# --- FEATURES --- #\n",
        "####################\n",
        "\n",
        "# Features dir\n",
        "FEATURES_DIR = MAIN_DIR + \"/features\"\n",
        "\n",
        "# Features paths\n",
        "FEATURES_CORRELATION = FEATURES_DIR + \"/\" + FEATURES_CORRELATION_LABEL + \".json\"\n",
        "BASE_FEATURES = FEATURES_DIR + \"/\" + BASE_FEATURES_LABEL + \".json\"\n",
        "BASE_AND_MOST_CORR_FEATURES = FEATURES_DIR + \"/\" + BASE_AND_MOST_CORR_FEATURES_LABEL + \".json\"\n",
        "BASE_AND_LEAST_CORR_FEATURES = FEATURES_DIR + \"/\" + BASE_AND_LEAST_CORR_FEATURES_LABEL + \".json\"\n",
        "\n",
        "##################\n",
        "# --- MODELS --- #\n",
        "##################\n",
        "\n",
        "# Model dir\n",
        "MODELS_DIR = MAIN_DIR + \"/models\"\n",
        "\n",
        "# Model path\n",
        "LR_MODEL = MODELS_DIR + \"/\" + LR_MODEL_NAME\n",
        "GLR_MODEL = MODELS_DIR + \"/\" + GLR_MODEL_NAME\n",
        "RF_MODEL = MODELS_DIR + \"/\" + RF_MODEL_NAME\n",
        "GBTR_MODEL = MODELS_DIR + \"/\" + GBTR_MODEL_NAME\n",
        "\n",
        "###################\n",
        "# --- RESULTS --- #\n",
        "###################\n",
        "\n",
        "# Results dir\n",
        "RESULTS_DIR = MAIN_DIR + \"/results\"\n",
        "RESULTS_FINAL_DIR = RESULTS_DIR + \"/final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX7xDYw4SvrB"
      },
      "outputs": [],
      "source": [
        "# Suppression of warnings for better reading\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "pio.renderers.default = 'vscode+colab' # To correctly render plotly plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcQR_Y-kn5oq"
      },
      "source": [
        "# Create the pyspark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0FWUAvCn5oq"
      },
      "outputs": [],
      "source": [
        "# Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '109G').\\\n",
        "                set(\"spark.kryoserializer.buffer.max\", \"1G\").\\\n",
        "                setAppName(\"BitcoinPricePrediction\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0yi3Fcth9fi"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiF49OXz4-i7"
      },
      "outputs": [],
      "source": [
        "# Load datasets into pyspark dataset objects\n",
        "df = spark.read.load(DATASET_TEST,\n",
        "                         format=\"parquet\",\n",
        "                         sep=\",\",\n",
        "                         inferSchema=\"true\",\n",
        "                         header=\"true\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLj6RJRcmLtl",
        "outputId": "ab153263-9cbe-43ef-c5c0-46bcd4516626"
      },
      "outputs": [],
      "source": [
        "final_scores_utilities.dataset_info(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmSuP_nGbNF-"
      },
      "source": [
        "# Compare train / validation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTcStzrESPXd"
      },
      "outputs": [],
      "source": [
        "splits_list = [BLOCK_SPLITS_NAME, WALK_FORWARD_SPLITS_NAME, SHORT_TERM_SPLITS_NAME]\n",
        "models_list = [LR_MODEL_NAME, GLR_MODEL_NAME, RF_MODEL_NAME, GBTR_MODEL_NAME]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkG0w1Y16xen"
      },
      "outputs": [],
      "source": [
        "# Load all results\n",
        "train_valid_all_results_raw = final_scores_utilities.get_all_results(splits_list, models_list, RESULTS_DIR) # Get all results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MRAPRjG6xen"
      },
      "outputs": [],
      "source": [
        "train_valid_all_results = train_valid_all_results_raw[train_valid_all_results_raw['Dataset'] != 'train'].copy() # Remove the 'train' dataset\n",
        "\n",
        "train_valid_all_results = final_scores_utilities.train_valid_dataset_fine_tuning(train_valid_all_results, 'results') # Fine tuning of the dataset\n",
        "train_valid_all_results = train_valid_all_results[(train_valid_all_results['Dataset'] == 'valid') & (train_valid_all_results['Type'] == 'Default')] # Get only the default results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzYcbMGq6xen"
      },
      "source": [
        "## RMSE and R2 values compared with the features used in the default models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K80aQp4s6xen",
        "outputId": "b9c5d229-7fdd-4ef4-bb44-e8c780b9f4d2"
      },
      "outputs": [],
      "source": [
        "rmse_title = 'RMSE per Features type'\n",
        "r2_title = 'R2 per Features type'\n",
        "save_path = RESULTS_FINAL_DIR + \"/plots/default_\"\n",
        "final_scores_utilities.train_val_rmse_r2_plot(train_valid_all_results, 'Features', 'Model', 'RMSE', 'R2', 'Splitting', rmse_title, r2_title, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBU5nymkWIXR"
      },
      "source": [
        "❗TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "qtS2iXPXY_lx",
        "outputId": "664f06cd-0a8a-45b4-c0a1-f4cb945a9d5e"
      },
      "outputs": [],
      "source": [
        "# Exclude negative R2 values\n",
        "train_valid_all_results_non_negative = train_valid_all_results[train_valid_all_results['R2'] >= 0].copy()\n",
        "\n",
        "# # Convert the columns to a category type with the custom order\n",
        "train_valid_all_results_non_negative['Features'] = pd.Categorical(train_valid_all_results_non_negative['Features'], categories=final_scores_utilities.features_order, ordered=True)\n",
        "train_valid_all_results_non_negative['Splitting'] = pd.Categorical(train_valid_all_results_non_negative['Splitting'], categories=final_scores_utilities.splitting_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the columns\n",
        "train_valid_all_results_non_negative.sort_values(by=['Features', 'Splitting'], inplace=True)\n",
        "\n",
        "r2_title = 'R2 per Model type (non-negative)'\n",
        "final_scores_utilities.train_val_r2_plot(train_valid_all_results_non_negative, 'Features', 'Model', 'R2', 'Splitting', r2_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EhKlN406xen"
      },
      "source": [
        "❗ TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEfAIhHlbNF-"
      },
      "outputs": [],
      "source": [
        "# Load relevant results\n",
        "train_valid_results_raw, train_valid_accuracy_raw = final_scores_utilities.get_rel_results(splits_list, models_list, RESULTS_DIR) # Get relevant results\n",
        "\n",
        "train_valid_results = final_scores_utilities.train_valid_dataset_fine_tuning(train_valid_results_raw.copy(), 'results') # Fine tuning of the dataset\n",
        "train_valid_accuracy = final_scores_utilities.train_valid_dataset_fine_tuning(train_valid_accuracy_raw.copy(), 'accuracy') # Fine tuning of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "V3B1QiKTlJS0",
        "outputId": "9f8ae3e8-0868-42f5-fbbc-93f631208aca"
      },
      "outputs": [],
      "source": [
        "train_valid_results = final_scores_utilities.train_valid_dataset_fine_tuning(train_valid_results, 'results')\n",
        "train_valid_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "MsssJNJclJS0",
        "outputId": "1b248332-cebd-47ae-db85-15ea5feba8c9"
      },
      "outputs": [],
      "source": [
        "train_valid_accuracy = final_scores_utilities.train_valid_dataset_fine_tuning(train_valid_accuracy, 'accuracy')\n",
        "train_valid_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DTP_7e86xeo"
      },
      "source": [
        "## RMSE and R2 values compared between default and tuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wzW9cTV06xeo",
        "outputId": "7fd15bc8-7457-45c8-88a9-44fd030cd110"
      },
      "outputs": [],
      "source": [
        "rmse_title = 'RMSE per Model type'\n",
        "r2_title = 'R2 per Model type'\n",
        "save_path = RESULTS_FINAL_DIR + \"/plots/final_\"\n",
        "final_scores_utilities.train_val_rmse_r2_plot(train_valid_results, 'Type', 'Model', 'RMSE', 'R2', 'Splitting', rmse_title, r2_title, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGDD2G8b6xeo"
      },
      "source": [
        "❗ TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "P8FVzZesdZ9U",
        "outputId": "82fc206a-f3f3-49c3-dfda-9861db26adf5"
      },
      "outputs": [],
      "source": [
        "# Exclude negative R2 values\n",
        "train_valid_results_non_negative = train_valid_results[train_valid_results['R2'] >= 0].copy()\n",
        "\n",
        "# # Convert the columns to a category type with the custom order\n",
        "train_valid_results_non_negative['Type'] = pd.Categorical(train_valid_results_non_negative['Type'], categories=final_scores_utilities.type_order, ordered=True)\n",
        "train_valid_results_non_negative['Model'] = pd.Categorical(train_valid_results_non_negative['Model'], categories=final_scores_utilities.model_order, ordered=True)\n",
        "train_valid_results_non_negative['Splitting'] = pd.Categorical(train_valid_results_non_negative['Splitting'], categories=final_scores_utilities.splitting_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the columns\n",
        "train_valid_results_non_negative.sort_values(by=['Splitting', 'Type', 'Model'], inplace=True)\n",
        "\n",
        "r2_title = 'R2 per Model type (non-negative)'\n",
        "final_scores_utilities.train_val_r2_plot(train_valid_results_non_negative, 'Type', 'Model', 'R2', 'Splitting', r2_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IbmASOoQayB"
      },
      "source": [
        "❗ TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2mVHTOF6xeo"
      },
      "source": [
        "## Accuracy percentage compared between default and tuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "xU7q9c44No5x",
        "outputId": "0cf25d99-500d-452e-cef9-e83de6bf1acd"
      },
      "outputs": [],
      "source": [
        "# Group by 'Splitting'\n",
        "train_valid_accuracy_grouped = train_valid_accuracy.groupby('Splitting')\n",
        "\n",
        "title = 'Percentage of accuracy between default and tuned model'\n",
        "save_path = RESULTS_FINAL_DIR + \"/plots/final_\"\n",
        "final_scores_utilities.train_val_accuracy_plot(train_valid_accuracy_grouped, 'Model', 'Accuracy (default)', 'Accuracy (tuned)', title, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN0xvqm9lJS1"
      },
      "source": [
        "❗TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OInWyb7C5jA"
      },
      "source": [
        "# Test models\n",
        "After loading the trained models, the test set is divided into further mini-sets of `1 week`, `15 days`, `1 month` and `3 months` to see how the models' performance degrades as time increases. Final results are collected and compared to draw conclusions (see final results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCS3oS4NJVN0"
      },
      "outputs": [],
      "source": [
        "# Retrieve the last value of the timestamp column\n",
        "first_timestamp = df.select(col(\"timestamp\")).first()[0]\n",
        "\n",
        "# Split the test set into mini-sets of 1 week, 15 days, 1 month, and 3 months\n",
        "one_week_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(weeks=1))\n",
        "fifteen_days_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(days=15))\n",
        "one_month_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(months=1))\n",
        "three_months_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(months=3))\n",
        "\n",
        "# Save datasets\n",
        "datasets_list = [one_week_df, fifteen_days_df, one_month_df, three_months_df]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "VOQc2uOgnpuC",
        "outputId": "da91a33c-be88-4ce6-bea9-53fcf1027c8e"
      },
      "outputs": [],
      "source": [
        "final_scores_utilities.show_datasets(one_week_df.toPandas(), fifteen_days_df.toPandas(), one_month_df.toPandas(), three_months_df.toPandas(), \"Test set split\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tXCxzQIf9yB"
      },
      "source": [
        "In this graph each split is overlaid with the others, to view them individually turn on / off the elements in the legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeYYomFJHTRD",
        "outputId": "75fa0f99-40ce-4eae-819a-2a0c29b040fa"
      },
      "outputs": [],
      "source": [
        "# Loading base features\n",
        "with open(BASE_FEATURES, \"r\") as f:\n",
        "    BASE_FEATURES = json.load(f)\n",
        "print(BASE_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMNZjOxDHTn7",
        "outputId": "0c48c45f-5de7-493d-d8a0-769d6ff9ac4f"
      },
      "outputs": [],
      "source": [
        "# Loading currency and additional most correlated features\n",
        "with open(BASE_AND_MOST_CORR_FEATURES, \"r\") as f:\n",
        "    BASE_AND_MOST_CORR_FEATURES = json.load(f)\n",
        "print(BASE_AND_MOST_CORR_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfx1z5t2lJS2",
        "outputId": "04dda172-e8a8-4318-eff8-66bb5ca3d542"
      },
      "outputs": [],
      "source": [
        "# Loading currency and additional least correlated features\n",
        "with open(BASE_AND_LEAST_CORR_FEATURES, \"r\") as f:\n",
        "    BASE_AND_LEAST_CORR_FEATURES = json.load(f)\n",
        "print(BASE_AND_LEAST_CORR_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l8lj8kVcaFK"
      },
      "outputs": [],
      "source": [
        "# Load models\n",
        "lr = PipelineModel.load(LR_MODEL)\n",
        "glr = PipelineModel.load(GLR_MODEL)\n",
        "rf = PipelineModel.load(RF_MODEL)\n",
        "gbtr = PipelineModel.load(GBTR_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62HA_gB7LK1Z",
        "outputId": "83caa8f6-0205-4fd8-fa7d-ce605083fa9d"
      },
      "outputs": [],
      "source": [
        "# Group models and features\n",
        "features_list = [BASE_FEATURES, BASE_AND_MOST_CORR_FEATURES, BASE_AND_LEAST_CORR_FEATURES]\n",
        "models_list = [lr, glr, rf, gbtr]\n",
        "\n",
        "# Get model parameters\n",
        "model_params_list = final_scores_utilities.get_model_parameters(train_valid_results_raw, models_list, features_list)\n",
        "print(model_params_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOcMCi4IhtR1"
      },
      "outputs": [],
      "source": [
        "final_test_results_raw, predictions_df = final_scores_utilities.models_testing(datasets_list, model_params_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af0uEhdmQM9k"
      },
      "source": [
        "# Final results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Wudhb5ZQjh--",
        "outputId": "a95fdc84-b2a6-4fea-e13a-7192b956b2d5"
      },
      "outputs": [],
      "source": [
        "final_test_results = final_scores_utilities.test_dataset_fine_tuning(final_test_results_raw.copy())\n",
        "final_test_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MtF954fLqkr"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mnGPB0P7JRji",
        "outputId": "e79fe1a0-5595-42b7-9037-90e8edd4a26e"
      },
      "outputs": [],
      "source": [
        "datasets_name_raw_list = [\"one_week\", \"fifteen_days\", \"one_month\", \"three_months\"]\n",
        "\n",
        "# For each dataset type, it displays the predicitons of each model\n",
        "for i, data in enumerate(datasets_list):\n",
        "    predictions_to_show = predictions_df[predictions_df['Dataset'] == datasets_name_raw_list[i]]\n",
        "\n",
        "    lr_predictions = predictions_to_show[predictions_to_show['Model'] == LR_MODEL_NAME]\n",
        "    glr_predictions = predictions_to_show[predictions_to_show['Model'] == GLR_MODEL_NAME]\n",
        "    rf_predictions = predictions_to_show[predictions_to_show['Model'] == RF_MODEL_NAME]\n",
        "    gbtr_predictions = predictions_to_show[predictions_to_show['Model'] == GBTR_MODEL_NAME]\n",
        "\n",
        "    final_scores_utilities.show_results(\n",
        "        data.toPandas(),\n",
        "        final_scores_utilities.model_order[0], lr_predictions,\n",
        "        final_scores_utilities.model_order[1], glr_predictions,\n",
        "        final_scores_utilities.model_order[2], rf_predictions,\n",
        "        final_scores_utilities.model_order[3], gbtr_predictions,\n",
        "        final_scores_utilities.dataset_order[i] + \" predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyafvhUxOFCw"
      },
      "source": [
        "❗TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy5jFb--Lv-m"
      },
      "source": [
        "## RMSE and R2 values of each model for each dataset split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R1eIAKYLKS5f",
        "outputId": "5dc35ffc-94cf-43c8-f926-fce584a4db64"
      },
      "outputs": [],
      "source": [
        "rmse_title = 'RMSE per Dataset type'\n",
        "r2_title = 'R2 per Dataset type'\n",
        "save_path = RESULTS_FINAL_DIR + \"/plots/final_\"\n",
        "final_scores_utilities.test_rmse_r2_plot(final_test_results, 'Model', 'RMSE', 'R2', 'Dataset', rmse_title, r2_title, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBGeWeopH0vn"
      },
      "source": [
        "❗TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "hZQ818sLOkC4",
        "outputId": "537b187c-41ed-452b-fb25-fdca2e9f570e"
      },
      "outputs": [],
      "source": [
        "# Exclude negative R2 values\n",
        "final_test_results_non_negative = final_test_results[final_test_results['R2'] >= 0].copy()\n",
        "\n",
        "# # Convert the columns to a category type with the custom order\n",
        "final_test_results_non_negative['Dataset'] = pd.Categorical(final_test_results_non_negative['Dataset'], categories=final_scores_utilities.dataset_order, ordered=True)\n",
        "final_test_results_non_negative['Model'] = pd.Categorical(final_test_results_non_negative['Model'], categories=final_scores_utilities.model_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the columns\n",
        "final_test_results_non_negative.sort_values(by=['Dataset', 'Model'], inplace=True)\n",
        "\n",
        "r2_title = 'R2 per Dataset type (non-negative)'\n",
        "final_scores_utilities.test_r2_plot(final_test_results_non_negative, 'Model', 'R2', 'Dataset', r2_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp67_5jGofRj"
      },
      "source": [
        "❗TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUTQDtfHMAiV"
      },
      "source": [
        "## Accuracy percentage of each model for each dataset split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "J6AadoP1KTI2",
        "outputId": "0104a74e-b6c5-4a27-a422-09603ca44c28"
      },
      "outputs": [],
      "source": [
        "# Group by 'Splitting'\n",
        "final_test_results_grouped = final_test_results.groupby('Dataset')\n",
        "\n",
        "title = 'Percentage of accuracy between default and tuned model'\n",
        "save_path = RESULTS_FINAL_DIR + \"/plots/final_\"\n",
        "final_scores_utilities.test_accuracy_plot(final_test_results_grouped, 'Model', 'Accuracy', title, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZUqhu9RofzF"
      },
      "source": [
        "❗TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba6TRcI6jYWk"
      },
      "source": [
        "# Saving final results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1V6Wca8Vp7n"
      },
      "outputs": [],
      "source": [
        "# Saving test results\n",
        "final_test_results_raw.to_csv(RESULTS_FINAL_DIR + \"/final.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvwOAHKet8Gr"
      },
      "outputs": [],
      "source": [
        "# Export notebook in html format (remember to save the notebook and change the model name)\n",
        "if LOCAL_RUNNING:\n",
        "    !jupyter nbconvert --to html 6-final-scores.ipynb --output 6-final-scores --output-dir='./exports'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "303fa613b6f3e1efefe7bb28036e305e1021fa6bdb083a5f9fd57f9d9bbad8eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
