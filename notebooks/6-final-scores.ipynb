{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e452Ydj7chNV"
      },
      "source": [
        "# **Bitcoin price prediction - Final scores**\n",
        "### Big Data Computing final project - A.Y. 2022 - 2023\n",
        "Prof. Gabriele Tolomei\n",
        "\n",
        "MSc in Computer Science\n",
        "\n",
        "La Sapienza, University of Rome\n",
        "\n",
        "### Author: Corsi Danilo (1742375) - corsi.1742375@studenti.uniroma1.it\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Description: display of final scores and making predictions on the test set with the models trained on the whole train / validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTGTgzEqE3x"
      },
      "source": [
        "# Global constants, dependencies, libraries and tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av93BTCYR815"
      },
      "outputs": [],
      "source": [
        "# Main constants\n",
        "LOCAL_RUNNING = False\n",
        "SLOW_OPERATIONS = True # Decide whether or not to use operations that might slow down notebook execution\n",
        "ROOT_DIR = \"D:/Documents/Repository/BDC/project\" if LOCAL_RUNNING else \"/content/drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZVTH76BiJps",
        "outputId": "d1abbdf7-aa64-4521-f62a-d16209502ed2"
      },
      "outputs": [],
      "source": [
        "if not LOCAL_RUNNING:\n",
        "    # Point Colaboratory to Google Drive\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Define GDrive paths\n",
        "    drive.mount(ROOT_DIR, force_remount=True)\n",
        "\n",
        "    # Install Spark and related dependencies\n",
        "    !pip install pyspark\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBRexBrot8Gg"
      },
      "source": [
        "## Import my utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGWKLtp9t8Gh"
      },
      "outputs": [],
      "source": [
        "# Set main dir\n",
        "MAIN_DIR = ROOT_DIR + \"\" if LOCAL_RUNNING else ROOT_DIR + \"/MyDrive/BDC/project\"\n",
        "\n",
        "# Utilities dir\n",
        "UTILITIES_DIR = MAIN_DIR + \"/utilities\"\n",
        "\n",
        "# Import my utilities\n",
        "import sys\n",
        "sys.path.append(UTILITIES_DIR)\n",
        "\n",
        "from imports import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVa9PkQ5R816"
      },
      "outputs": [],
      "source": [
        "# Set main dir\n",
        "MAIN_DIR = ROOT_DIR + \"\" if LOCAL_RUNNING else ROOT_DIR + \"/MyDrive/BDC/project\"\n",
        "\n",
        "###################\n",
        "# --- DATASET --- #\n",
        "###################\n",
        "\n",
        "# Datasets dirs\n",
        "DATASET_OUTPUT_DIR = MAIN_DIR + \"/datasets/output\"\n",
        "\n",
        "# Datasets names\n",
        "DATASET_TEST_NAME = \"bitcoin_blockchain_data_15min_test\"\n",
        "\n",
        "# Datasets paths\n",
        "DATASET_TEST = DATASET_OUTPUT_DIR + \"/\" + DATASET_TEST_NAME + \".parquet\"\n",
        "\n",
        "####################\n",
        "# --- FEATURES --- #\n",
        "####################\n",
        "\n",
        "# Features dir\n",
        "FEATURES_DIR = MAIN_DIR + \"/features\"\n",
        "\n",
        "# Features labels\n",
        "FEATURES_LABEL = \"features\"\n",
        "TARGET_LABEL = \"next-market-price\"\n",
        "\n",
        "# Features names\n",
        "ALL_FEATURES_NAME = \"all_features\"\n",
        "MOST_REL_FEATURES_NAME = \"most_rel_features\"\n",
        "LEAST_REL_FEATURES_NAME = \"least_rel_features\"\n",
        "\n",
        "# Features paths\n",
        "ALL_FEATURES = FEATURES_DIR + \"/\" + ALL_FEATURES_NAME + \".json\"\n",
        "MOST_REL_FEATURES = FEATURES_DIR + \"/\" + MOST_REL_FEATURES_NAME + \".json\"\n",
        "LEAST_REL_FEATURES = FEATURES_DIR + \"/\" + LEAST_REL_FEATURES_NAME + \".json\"\n",
        "\n",
        "##################\n",
        "# --- MODELS --- #\n",
        "##################\n",
        "\n",
        "# Model names\n",
        "LR_MODEL_NAME = \"LinearRegression\"\n",
        "GLR_MODEL_NAME = \"GeneralizedLinearRegression\"\n",
        "RF_MODEL_NAME = \"RandomForestRegressor\"\n",
        "GBT_MODEL_NAME = \"GradientBoostingTreeRegressor\"\n",
        "\n",
        "# Model dir\n",
        "MODELS_DIR = MAIN_DIR + \"/models\"\n",
        "\n",
        "# Model path\n",
        "LR_MODEL = MODELS_DIR + \"/\" + LR_MODEL_NAME\n",
        "GLR_MODEL = MODELS_DIR + \"/\" + GLR_MODEL_NAME\n",
        "RF_MODEL = MODELS_DIR + \"/\" + RF_MODEL_NAME\n",
        "GBT_MODEL = MODELS_DIR + \"/\" + GBT_MODEL_NAME\n",
        "\n",
        "###################\n",
        "# --- RESULTS --- #\n",
        "###################\n",
        "\n",
        "# splits names\n",
        "BLOCK_SPLITS_NAME = \"block_splits\"\n",
        "WALK_FORWARD_SPLITS_NAME = \"walk_forward_splits\"\n",
        "SHORT_TERM_SPLITS_NAME = \"single_split\"\n",
        "\n",
        "# Results dir\n",
        "RESULTS_DIR = MAIN_DIR + \"/results\"\n",
        "RESULTS_FINAL_DIR = RESULTS_DIR + \"/final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX7xDYw4SvrB"
      },
      "outputs": [],
      "source": [
        "# Suppression of warnings for better reading\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "if LOCAL_RUNNING: pio.renderers.default='notebook' # To correctly export the notebook in html format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcQR_Y-kn5oq"
      },
      "source": [
        "# Create the pyspark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0FWUAvCn5oq"
      },
      "outputs": [],
      "source": [
        "# Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '109G').\\\n",
        "                set(\"spark.kryoserializer.buffer.max\", \"1G\").\\\n",
        "                setAppName(\"BitcoinPricePrediction\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0yi3Fcth9fi"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiF49OXz4-i7"
      },
      "outputs": [],
      "source": [
        "# Load datasets into pyspark dataset objects\n",
        "df = spark.read.load(DATASET_TEST,\n",
        "                         format=\"parquet\",\n",
        "                         sep=\",\",\n",
        "                         inferSchema=\"true\",\n",
        "                         header=\"true\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVXM8roGmMNx"
      },
      "outputs": [],
      "source": [
        "def dataset_info(dataset):\n",
        "  # Print dataset\n",
        "  dataset.show(3)\n",
        "\n",
        "  # Get the number of rows\n",
        "  num_rows = dataset.count()\n",
        "\n",
        "  # Get the number of columns\n",
        "  num_columns = len(dataset.columns)\n",
        "\n",
        "  # Print the shape of the dataset\n",
        "  print(\"Shape:\", (num_rows, num_columns))\n",
        "\n",
        "  # Print the schema of the dataset\n",
        "  dataset.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLj6RJRcmLtl",
        "outputId": "f77b76e5-b202-4652-e953-3fa92fcabc86"
      },
      "outputs": [],
      "source": [
        "if SLOW_OPERATIONS:\n",
        "  dataset_info(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmSuP_nGbNF-"
      },
      "source": [
        "# Load train / validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "‚ùóTOFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEfAIhHlbNF-"
      },
      "outputs": [],
      "source": [
        "# Load models results\n",
        "splits_list = [BLOCK_SPLITS_NAME, WALK_FORWARD_SPLITS_NAME, SHORT_TERM_SPLITS_NAME]\n",
        "models_list = [LR_MODEL_NAME, GLR_MODEL_NAME, RF_MODEL_NAME, GBT_MODEL_NAME]\n",
        "train_valid_results = pd.DataFrame(columns=['Model', 'Type', 'Dataset', 'Splitting', 'Features', 'Parameters', 'RMSE', 'MSE', 'MAE', 'MAPE', 'R2', 'Adjusted_R2', 'Time'])\n",
        "train_valid_accuracy = pd.DataFrame(columns=['Model', 'Features', 'Splitting', 'Accuracy (default)', 'Accuracy (validated)'])\n",
        "for split in splits_list:\n",
        "    for model in models_list:\n",
        "        if split == BLOCK_SPLITS_NAME:\n",
        "            train_valid_results = pd.concat([train_valid_results, pd.read_csv(RESULTS_DIR + \"/\" + split + \"/\" + model + \"_rel.csv\")], ignore_index=True)\n",
        "            train_valid_accuracy = pd.concat([train_valid_accuracy, pd.read_csv(RESULTS_DIR + \"/\" + split + \"/\" + model + \"_accuracy.csv\")], ignore_index=True)\n",
        "        elif split == WALK_FORWARD_SPLITS_NAME:\n",
        "            train_valid_results = pd.concat([train_valid_results, pd.read_csv(RESULTS_DIR + \"/\" + split + \"/\" + model + \"_rel.csv\")], ignore_index=True)\n",
        "            train_valid_accuracy = pd.concat([train_valid_accuracy, pd.read_csv(RESULTS_DIR + \"/\" + split + \"/\" + model + \"_accuracy.csv\")], ignore_index=True)\n",
        "        elif split == SHORT_TERM_SPLITS_NAME:\n",
        "            train_valid_results = pd.concat([train_valid_results, pd.read_csv(RESULTS_DIR + \"/\" + split + \"/\" + model + \"_rel.csv\")], ignore_index=True)\n",
        "            train_valid_accuracy = pd.concat([train_valid_accuracy, pd.read_csv(RESULTS_DIR + \"/\" + split + \"/\" + model + \"_accuracy.csv\")], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "JSBMKeEh4tMG",
        "outputId": "0e02d317-0c20-4a97-a93e-63c8f7113fd4"
      },
      "outputs": [],
      "source": [
        "train_valid_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "cGfSmxmr4uHQ",
        "outputId": "2bd37747-9600-455c-f343-01658ddf0721"
      },
      "outputs": [],
      "source": [
        "train_valid_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QHHoanCHJ7b"
      },
      "outputs": [],
      "source": [
        "default_mask = train_valid_results['Type'].str.contains('default_norm|default')\n",
        "tuned_mask = train_valid_results['Type'].str.contains('final|tuned|cross_val')\n",
        "\n",
        "default_results = train_valid_results[default_mask]\n",
        "tuned_results = train_valid_results[tuned_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "hC60n4t0RMB8",
        "outputId": "b2e8147f-f1aa-423b-8aab-a82013b919d8"
      },
      "outputs": [],
      "source": [
        "default_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "2EX4zfv4RMPh",
        "outputId": "94567d32-d4ac-434a-ee67-cda0cd2c4462"
      },
      "outputs": [],
      "source": [
        "tuned_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxhoQK6iRvxs"
      },
      "outputs": [],
      "source": [
        "def results_bar_plot(dataset, title):\n",
        "  fig = px.bar(\n",
        "    x=dataset['Model'],\n",
        "    y=dataset['RMSE'],\n",
        "    color=dataset['Splitting'],\n",
        "    barmode='group'\n",
        "  )\n",
        "\n",
        "  fig.update_yaxes(side=\"left\", showticklabels=True)\n",
        "  fig.update_layout(title=title)\n",
        "  fig.update_layout(legend_title_text=\"Splitting methods\")\n",
        "  fig.update_yaxes(showticklabels=False)\n",
        "  fig.update_xaxes(title_text=\"Models\")\n",
        "  fig.update_yaxes(title='RMSE')\n",
        "\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6O4ZP7OKR3-B",
        "outputId": "861225e7-4380-46ca-fcf0-f0442a6b4ff9"
      },
      "outputs": [],
      "source": [
        "results_bar_plot(default_results, \"RMSE value for each default model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "uG9wviKOWEdY",
        "outputId": "16602be9-c2d7-4b80-960b-821f9be5d608"
      },
      "outputs": [],
      "source": [
        "results_bar_plot(tuned_results, \"RMSE value for each tuned model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6vsXyXhCn2B"
      },
      "outputs": [],
      "source": [
        "# def results_bar_plot(title):\n",
        "#   from plotly.subplots import make_subplots\n",
        "\n",
        "#   fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "#   fig1 = px.bar(\n",
        "#     x=default_results['Model'],\n",
        "#     y=default_results['RMSE'],\n",
        "#     color=default_results['Splitting'],\n",
        "#     barmode='group'\n",
        "#   )\n",
        "\n",
        "#   fig2 = px.bar(\n",
        "#     x=tuned_results['Model'],\n",
        "#     y=tuned_results['RMSE'],\n",
        "#     color=tuned_results['Splitting'],\n",
        "#     barmode='group'\n",
        "#   )\n",
        "\n",
        "#   # fig1.update_yaxes(side=\"left\", showticklabels=True)\n",
        "#   # fig1.update_layout(title=title)\n",
        "#   # fig1.update_layout(legend_title_text=\"Splitting methods\")\n",
        "#   # fig1.update_yaxes(showticklabels=False)\n",
        "#   # fig1.update_xaxes(title_text=\"Models\")\n",
        "#   # fig1.update_yaxes(title='RMSE')\n",
        "\n",
        "#   # fig2.update_yaxes(side=\"left\", showticklabels=True)\n",
        "#   # fig2.update_layout(title=title)\n",
        "#   # fig2.update_layout(legend_title_text=\"Splitting methods\")\n",
        "#   # fig2.update_yaxes(showticklabels=False)\n",
        "#   # fig2.update_xaxes(title_text=\"Models\")\n",
        "#   # fig2.update_yaxes(title='RMSE')\n",
        "\n",
        "#   # Add the traces to the subplot\n",
        "#   fig.add_trace(fig1.data[0], row=1, col=1)\n",
        "#   fig.add_trace(fig2.data[0], row=1, col=2)\n",
        "\n",
        "#   fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNeYxlV0Dh8J"
      },
      "outputs": [],
      "source": [
        "# results_bar_plot(\"RMSE value for each model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIDQqYl5HPAh"
      },
      "outputs": [],
      "source": [
        "def accuracy_bar_plot(dataset, accuracy, title):\n",
        "  fig = px.bar(\n",
        "    x=dataset['Model'],\n",
        "    y=dataset[accuracy],\n",
        "    color=dataset['Splitting'],\n",
        "    barmode='group'\n",
        "  )\n",
        "\n",
        "  fig.update_yaxes(side=\"left\", showticklabels=True)\n",
        "  fig.update_layout(title=title)\n",
        "  fig.update_layout(legend_title_text=\"Splitting methods\")\n",
        "  fig.update_yaxes(showticklabels=False)\n",
        "  fig.update_xaxes(title_text=\"Models\")\n",
        "  fig.update_yaxes(title='Accuracy')\n",
        "\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vrk2Vb0yHHrE",
        "outputId": "a9c17ae0-d596-434b-a7ca-37522e78770f"
      },
      "outputs": [],
      "source": [
        "accuracy_bar_plot(train_valid_accuracy, 'Accuracy (default)', \"Accuracy value for each default model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "9NYxZS7eL_Jp",
        "outputId": "ae701054-473c-4b3b-8838-71bf957b62db"
      },
      "outputs": [],
      "source": [
        "accuracy_bar_plot(train_valid_accuracy, 'Accuracy (validated)', \"Accuracy value for each tuned model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OInWyb7C5jA"
      },
      "source": [
        "# Test models\n",
        "For each model, predictions on the various mini-sets are made and the obtained results are compared.\n",
        "\n",
        "The test set is divided into further mini-sets of 1 week, 15 days, 1 month and 3 months to see how the models' performance degrades as the time taken into account increases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCS3oS4NJVN0"
      },
      "outputs": [],
      "source": [
        "# Retrieve the last value of the timestamp column\n",
        "first_timestamp = df.select(col(\"timestamp\")).first()[0]\n",
        "\n",
        "# Split the test set into mini-sets of 1 week, 15 days, 1 month, and 3 months\n",
        "one_week_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(weeks=1))\n",
        "fifteen_days_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(days=15))\n",
        "one_month_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(months=1))\n",
        "three_months_df = df.filter(col(\"timestamp\") <= first_timestamp + relativedelta(months=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwFhOSKCT49n"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Description: Evaluate final model by making predictions on the test set\n",
        "Args:\n",
        "    dataset: The dataSet which needs to be splited\n",
        "    dataset_name: Name of selected dataset [one_week | fifteen_days | one_month | three_months]\n",
        "    model: Trained model\n",
        "    model_name: Model name selected\n",
        "    features_normalization: Indicates whether features should be normalized (True) or not (False)\n",
        "    features: Features to be used to make predictions\n",
        "    features_name: Name of features used\n",
        "    features_label: The column name of features\n",
        "    target_label: The column name of target variable\n",
        "Return:\n",
        "    results_df: Results obtained from the evaluation\n",
        "    predictions: Predictions obtained from the model\n",
        "'''\n",
        "def evaluate_final_model(dataset, dataset_name, model, model_name, features_normalization, features, features_name, features_label, target_label):\n",
        "    # Select the type of features to be used\n",
        "    dataset = utilities.select_features(dataset, features_normalization, features, features_label, target_label)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.transform(dataset).select(target_label, \"market-price\", \"prediction\", 'timestamp')\n",
        "\n",
        "    # Compute validation error by several evaluators\n",
        "    eval_res = utilities.model_evaluation(target_label, predictions)\n",
        "\n",
        "    # Use dict to store each result\n",
        "    results = {\n",
        "        \"Model\": model_name,\n",
        "        \"Dataset\": dataset_name,\n",
        "        \"Features\": features_name,\n",
        "        \"RMSE\": eval_res['rmse'],\n",
        "        \"MSE\": eval_res['mse'],\n",
        "        \"MAE\": eval_res['mae'],\n",
        "        \"MAPE\": eval_res['mape'],\n",
        "        \"R2\": eval_res['r2'],\n",
        "        \"Adjusted_R2\": eval_res['adj_r2'],\n",
        "    }\n",
        "\n",
        "    # Transform dict to pandas dataset\n",
        "    results_pd = pd.DataFrame(results, index=[0])\n",
        "\n",
        "    return results_pd, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c4gbo9rbNF_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Description: How good the models are at predicting whether the price will go up or down\n",
        "Args:\n",
        "    dataset: The dataset which needs to be splited\n",
        "Return:\n",
        "    accuracy: Return the percentage of correct predictions\n",
        "'''\n",
        "def model_accuracy(dataset):\n",
        "    # Compute the number of total rows in the DataFrame.\n",
        "    total_rows = dataset.count()\n",
        "\n",
        "    # Create a column \"correct_prediction\" which is worth 1 if the prediction is correct, otherwise 0\n",
        "    dataset = dataset.withColumn(\n",
        "        \"correct_prediction\",\n",
        "        (\n",
        "            (col(\"market-price\") < col(\"next-market-price\")) & (col(\"market-price\") < col(\"prediction\"))\n",
        "        ) | (\n",
        "            (col(\"market-price\") > col(\"next-market-price\")) & (col(\"market-price\") > col(\"prediction\"))\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Count the number of correct predictions\n",
        "    correct_predictions = dataset.filter(col(\"correct_prediction\")).count()\n",
        "\n",
        "    # Compite percentage of correct predictions\n",
        "    accuracy = (correct_predictions / total_rows) * 100\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeYYomFJHTRD",
        "outputId": "b3beac50-faaa-41cf-c94d-de03228bd2a1"
      },
      "outputs": [],
      "source": [
        "# Loading all the features\n",
        "with open(ALL_FEATURES, \"r\") as f:\n",
        "    ALL_FEATURES = json.load(f)\n",
        "print(ALL_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMNZjOxDHTn7",
        "outputId": "ec05fb49-353d-4101-ae89-b4ed17e29f19"
      },
      "outputs": [],
      "source": [
        "# Loading the most relevant features\n",
        "with open(MOST_REL_FEATURES, \"r\") as f:\n",
        "    MOST_REL_FEATURES = json.load(f)\n",
        "print(MOST_REL_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l8lj8kVcaFK"
      },
      "outputs": [],
      "source": [
        "# Load models\n",
        "lr = PipelineModel.load(LR_MODEL)\n",
        "glr = PipelineModel.load(GLR_MODEL)\n",
        "rf = PipelineModel.load(RF_MODEL)\n",
        "gbt = PipelineModel.load(GBT_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "QBWWhtBsbNGA",
        "outputId": "f5e8b205-119b-40d4-8ab3-816bc4f46a42"
      },
      "outputs": [],
      "source": [
        "# Test models\n",
        "model_name_list = [LR_MODEL_NAME, GLR_MODEL_NAME, RF_MODEL_NAME, GBT_MODEL_NAME]\n",
        "model_list = [lr, glr, rf, gbt]\n",
        "dataset_list = [one_week_df, fifteen_days_df, one_month_df, three_months_df]\n",
        "dataset_name_list = [\"one_week\", \"fifteen_days\", \"one_month\", \"three_months\"]\n",
        "predictions_df = pd.DataFrame(columns=[TARGET_LABEL, \"market-price\", \"prediction\", 'timestamp'])\n",
        "test_results = pd.DataFrame(columns=['Model', 'Dataset', 'Features', 'RMSE', 'MSE', 'MAE', 'MAPE', 'R2', 'Adjusted_R2'])\n",
        "test_accuracy = pd.DataFrame(columns=['Model', 'Features', 'Dataset', 'Accuracy'])\n",
        "\n",
        "# For each model makes predictions based on the dataset type\n",
        "for i, model in enumerate(model_list):\n",
        "    for j, dataset in enumerate(dataset_list):\n",
        "        # Select the type of feature to be used based on the model\n",
        "        if (model_name_list[i] == LR_MODEL_NAME) or (model_name_list[i] == GLR_MODEL_NAME):\n",
        "          FEATURES_NORMALIZATION = True\n",
        "          CHOSEN_FEATURES = ALL_FEATURES\n",
        "          CHOSEN_FEATURES_LABEL = ALL_FEATURES_NAME\n",
        "        elif (model_name_list[i] == RF_MODEL_NAME) or (model_name_list[i] == GBT_MODEL_NAME):\n",
        "          FEATURES_NORMALIZATION = True\n",
        "          CHOSEN_FEATURES = MOST_REL_FEATURES\n",
        "          CHOSEN_FEATURES_LABEL = MOST_REL_FEATURES_NAME\n",
        "\n",
        "        results, predictions = evaluate_final_model(dataset, dataset_name_list[j], model, model_name_list[i], FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)\n",
        "        test_results = pd.concat([test_results, results], ignore_index=True)\n",
        "\n",
        "        predictions = predictions.withColumn(\"Model\", lit(model_name_list[i])).withColumn(\"Dataset\", lit(dataset_name_list[j]))\n",
        "        predictions_df = pd.concat([predictions_df, predictions.toPandas()], ignore_index=True)\n",
        "\n",
        "        accuracy = model_accuracy(predictions)\n",
        "        accuracy_data = {\n",
        "            'Model': model_name_list[i],\n",
        "            'Features': CHOSEN_FEATURES_LABEL,\n",
        "            'Dataset': dataset_name_list[j],\n",
        "            'Accuracy': accuracy\n",
        "        }\n",
        "        accuracy_data_df = pd.DataFrame(accuracy_data, index=['Model'])\n",
        "\n",
        "        test_accuracy = pd.concat([test_accuracy, accuracy_data_df], ignore_index=True)\n",
        "\n",
        "# Merge results and accuracy\n",
        "merged_results = pd.merge(test_results, test_accuracy)\n",
        "merged_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqzjoDuSC8sz"
      },
      "source": [
        "# Models comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14G_DwnlHPFU"
      },
      "outputs": [],
      "source": [
        "def show_results(predictions, model0_name, model0_predictions, model1_name, model1_predictions, model2_name, model2_predictions, model3_name, model3_predictions, title):\n",
        "  trace1 = go.Scatter(\n",
        "      x = predictions['timestamp'],\n",
        "      y = predictions['next-market-price'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = 'Next Market price (usd)'\n",
        "  )\n",
        "\n",
        "  trace2 = go.Scatter(\n",
        "      x = model0_predictions['timestamp'],\n",
        "      y = model0_predictions['prediction'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = model0_name + ' predictions'\n",
        "  )\n",
        "\n",
        "  trace3 = go.Scatter(\n",
        "      x = model1_predictions['timestamp'],\n",
        "      y = model1_predictions['prediction'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = model1_name + ' predictions'\n",
        "  )\n",
        "\n",
        "  trace4 = go.Scatter(\n",
        "      x = model2_predictions['timestamp'],\n",
        "      y = model2_predictions['prediction'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = model2_name + ' predictions'\n",
        "  )\n",
        "\n",
        "  trace5 = go.Scatter(\n",
        "      x = model3_predictions['timestamp'],\n",
        "      y = model3_predictions['prediction'].astype(float),\n",
        "      mode = 'lines',\n",
        "      name = model3_name + ' predictions'\n",
        "  )\n",
        "\n",
        "  layout = dict(\n",
        "      title=title + \" predictions\",\n",
        "      xaxis=dict(\n",
        "          rangeselector=dict(\n",
        "              buttons=list([\n",
        "                  # Change the count to desired amount of months.\n",
        "                  dict(count=1,\n",
        "                      label='1m',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(count=6,\n",
        "                      label='6m',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(count=12,\n",
        "                      label='1y',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(count=36,\n",
        "                      label='3y',\n",
        "                      step='month',\n",
        "                      stepmode='backward'),\n",
        "                  dict(step='all')\n",
        "              ])\n",
        "          ),\n",
        "          rangeslider=dict(\n",
        "              visible = True\n",
        "          ),\n",
        "          type='date'\n",
        "      )\n",
        "  )\n",
        "\n",
        "  data = [trace1,trace2,trace3,trace4,trace5]\n",
        "  fig = dict(data=data, layout=layout)\n",
        "  iplot(fig, filename = title + \" predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8zVaRQFNnEta",
        "outputId": "100a5c5a-e694-49fc-a14e-abf88ed86334"
      },
      "outputs": [],
      "source": [
        "# For each dataset type, it displays the predicitons of each model\n",
        "for dataset_name in dataset_name_list:\n",
        "    predictions_to_show = predictions_df[predictions_df['Dataset'] == dataset_name]\n",
        "\n",
        "    model_0_predictions = predictions_to_show[predictions_to_show['Model'] == model_name_list[0]]\n",
        "    model_1_predictions = predictions_to_show[predictions_to_show['Model'] == model_name_list[1]]\n",
        "    model_2_predictions = predictions_to_show[predictions_to_show['Model'] == model_name_list[2]]\n",
        "    model_3_predictions = predictions_to_show[predictions_to_show['Model'] == model_name_list[3]]\n",
        "\n",
        "    show_results(predictions_to_show, model_name_list[0], model_0_predictions, model_name_list[1], model_1_predictions, model_name_list[2], model_2_predictions, model_name_list[3], model_3_predictions, dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af0uEhdmQM9k"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "W2igZB0v5A5I",
        "outputId": "1ed3da4f-0a4e-4fc3-de9b-df4bd62e28dd"
      },
      "outputs": [],
      "source": [
        "scatter_plot(test_results, \"RMSE\", \"Model\", \"RMSE value for each model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ThWP3pTVcpfY",
        "outputId": "5a8b4758-1e88-403e-c992-a7e21cfe2c79"
      },
      "outputs": [],
      "source": [
        "adv_scatter_plot(test_results, \"RMSE\", \"Model\", \"Dataset\", \"RMSE value for each model (and dataset type)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "yNTaMZyyiE8k",
        "outputId": "5cad0e53-3b43-44bc-c64e-92eb3361296e"
      },
      "outputs": [],
      "source": [
        "scatter_plot(test_accuracy, \"Accuracy\", \"Model\", \"Accuracy for each model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8QZYesEciFIC",
        "outputId": "ce348e33-74fe-4a49-dc62-6ebc82c8db6f"
      },
      "outputs": [],
      "source": [
        "adv_scatter_plot(test_accuracy, \"Accuracy\", \"Model\", \"Dataset\", \"Accuracy for each model (and dataset type)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1V6Wca8Vp7n"
      },
      "outputs": [],
      "source": [
        "# Saving final test results\n",
        "test_results.to_csv(RESULTS_FINAL_DIR + \"/final.csv\", index=False)\n",
        "test_accuracy.to_csv(RESULTS_FINAL_DIR + \"/final_accuracy.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvwOAHKet8Gr"
      },
      "outputs": [],
      "source": [
        "# Export notebook in html format (remember to save the notebook and change the model name)\n",
        "if LOCAL_RUNNING:\n",
        "    !jupyter nbconvert --to html 6-final-scores.ipynb --output 6-final-scores --output-dir='./exports'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "303fa613b6f3e1efefe7bb28036e305e1021fa6bdb083a5f9fd57f9d9bbad8eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
