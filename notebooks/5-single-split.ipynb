{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xm5Q2vdDoc8"
      },
      "source": [
        "# **Bitcoin price prediction - Single Split**\n",
        "### Big Data Computing final project - A.Y. 2022 - 2023\n",
        "Prof. Gabriele Tolomei\n",
        "\n",
        "MSc in Computer Science\n",
        "\n",
        "La Sapienza, University of Rome\n",
        "\n",
        "### Author: Corsi Danilo (1742375) - corsi.1742375@studenti.uniroma1.it\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Description: executing the chosen model, first with default values, then by choosing the best parameters by performing hyperparameter tuning with cross validation and performance evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFaTBxjkDoc_"
      },
      "source": [
        "# Global constants, dependencies, libraries and tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSgxH69qDoc_"
      },
      "outputs": [],
      "source": [
        "# Main constants\n",
        "LOCAL_RUNNING = True\n",
        "SLOW_OPERATIONS = True # Decide whether or not to use operations that might slow down notebook execution\n",
        "ROOT_DIR = \"D:/Documents/Repository/BDC/project\" if LOCAL_RUNNING else \"/content/drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2BjmunuDodA",
        "outputId": "2defb2af-b7fe-4732-b3c6-54e205d51da9"
      },
      "outputs": [],
      "source": [
        "if not LOCAL_RUNNING:\n",
        "    # Point Colaboratory to Google Drive\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Define GDrive paths\n",
        "    drive.mount(ROOT_DIR, force_remount=True)\n",
        "\n",
        "    # Install Spark and related dependencies\n",
        "    !pip install pyspark\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import my utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05L2ouBFDodB"
      },
      "outputs": [],
      "source": [
        "# Set main dir\n",
        "MAIN_DIR = ROOT_DIR + \"\" if LOCAL_RUNNING else ROOT_DIR + \"/MyDrive/BDC/project\"\n",
        "\n",
        "# Utilities dir\n",
        "UTILITIES_DIR = MAIN_DIR + \"/utilities\"\n",
        "\n",
        "# Import my utilities\n",
        "import sys\n",
        "sys.path.append(UTILITIES_DIR)\n",
        "\n",
        "from imports import *\n",
        "import utilities, parameters\n",
        "\n",
        "importlib.reload(utilities)\n",
        "importlib.reload(parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Core variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BS = Block Split\n",
        "# WFS = Walk Forward Split\n",
        "# SS = Single Split\n",
        "SPLITTING_METHOD = parameters.SS \n",
        "\n",
        "# LR = LinearRegression \n",
        "# GLR = GeneralizedLinearRegression \n",
        "# RF = RandomForestRegressor \n",
        "# GBTR = GradientBoostingTreeRegressor\n",
        "MODEL_NAME = parameters.LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###################\n",
        "# --- DATASET --- #\n",
        "###################\n",
        "\n",
        "# Datasets dirs\n",
        "DATASET_OUTPUT_DIR = MAIN_DIR + \"/datasets/output\"\n",
        "\n",
        "# Datasets names\n",
        "DATASET_TRAIN_VALID_NAME = \"bitcoin_blockchain_data_15min_train_valid\"\n",
        "\n",
        "# Datasets paths\n",
        "DATASET_TRAIN_VALID  = DATASET_OUTPUT_DIR + \"/\" + DATASET_TRAIN_VALID_NAME + \".parquet\"\n",
        "\n",
        "####################\n",
        "# --- FEATURES --- #\n",
        "####################\n",
        "\n",
        "# Features dir\n",
        "FEATURES_DIR = MAIN_DIR + \"/features\"\n",
        "\n",
        "# Features labels\n",
        "FEATURES_LABEL = \"features\"\n",
        "TARGET_LABEL = \"next-market-price\"\n",
        "\n",
        "# Features names\n",
        "FEATURES_CORRELATION_NAME = \"features_correlation\"\n",
        "CURRENCY_FEATURES_NAME = \"currency_features\"\n",
        "CURRENCY_MOST_CORR_FEATURES_NAME = \"currency_most_corr_features\"\n",
        "CURRENCY_LEAST_CORR_FEATURES_NAME = \"currency_least_corr_features\"\n",
        "\n",
        "# Features paths\n",
        "FEATURES_CORRELATION = FEATURES_DIR + \"/\" + FEATURES_CORRELATION_NAME + \".json\"\n",
        "CURRENCY_FEATURES = FEATURES_DIR + \"/\" + CURRENCY_FEATURES_NAME + \".json\"\n",
        "CURRENCY_MOST_CORR_FEATURES = FEATURES_DIR + \"/\" + CURRENCY_MOST_CORR_FEATURES_NAME + \".json\"\n",
        "CURRENCY_LEAST_CORR_FEATURES = FEATURES_DIR + \"/\" + CURRENCY_LEAST_CORR_FEATURES_NAME + \".json\"\n",
        "\n",
        "##################\n",
        "# --- MODELS --- #\n",
        "##################\n",
        "\n",
        "# Model dir\n",
        "MODELS_DIR = MAIN_DIR + \"/models\"\n",
        "\n",
        "# Model path\n",
        "MODEL = MODELS_DIR + \"/\" + MODEL_NAME\n",
        "\n",
        "###################\n",
        "# --- RESULTS --- #\n",
        "###################\n",
        "\n",
        "# Results dir\n",
        "RESULTS_DIR = MAIN_DIR + \"/results/\" + SPLITTING_METHOD\n",
        "\n",
        "# Results path\n",
        "ALL_MODEL_RESULTS  = RESULTS_DIR + \"/\" + MODEL_NAME + \"_all.csv\"\n",
        "REL_MODEL_RESULTS  = RESULTS_DIR + \"/\" + MODEL_NAME + \"_rel.csv\"\n",
        "\n",
        "MODEL_ACCURACY_RESULTS  = RESULTS_DIR + \"/\" + MODEL_NAME + \"_accuracy.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing useful libraries\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "if LOCAL_RUNNING: pio.renderers.default='notebook' # To correctly export the notebook in html format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHtUnGFHDodF"
      },
      "source": [
        "# Create the pyspark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv8S8qm9DodF"
      },
      "outputs": [],
      "source": [
        "# Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '109G').\\\n",
        "                set(\"spark.kryoserializer.buffer.max\", \"1G\").\\\n",
        "                setAppName(\"BitcoinPricePrediction\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVWzuZF2DodG"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypesRPbdDodG"
      },
      "outputs": [],
      "source": [
        "# Load train / validation set into pyspark dataset objects\n",
        "df = spark.read.load(DATASET_TRAIN_VALID,\n",
        "                         format=\"parquet\",\n",
        "                         sep=\",\",\n",
        "                         inferSchema=\"true\",\n",
        "                         header=\"true\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYlLh3l2DodH"
      },
      "outputs": [],
      "source": [
        "def dataset_info(dataset):\n",
        "  # Print dataset\n",
        "  dataset.show(3)\n",
        "\n",
        "  # Get the number of rows\n",
        "  num_rows = dataset.count()\n",
        "\n",
        "  # Get the number of columns\n",
        "  num_columns = len(dataset.columns)\n",
        "\n",
        "  # Print the shape of the dataset\n",
        "  print(\"Shape:\", (num_rows, num_columns))\n",
        "\n",
        "  # Print the schema of the dataset\n",
        "  dataset.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fktk1rgeDodH",
        "outputId": "ab88103d-02bd-4327-a244-5f566f3d9492"
      },
      "outputs": [],
      "source": [
        "if SLOW_OPERATIONS:\n",
        "  dataset_info(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of considering the entire dataset, I will only consider the last two years from today's date in order to train / validate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVhSpEQLDodI"
      },
      "outputs": [],
      "source": [
        "# Retrieve the last timestamp value\n",
        "last_value = df.agg(last(\"timestamp\")).collect()[0][0]\n",
        "\n",
        "# Consider only the last two years as of today\n",
        "split_date = last_value - relativedelta(years=2)\n",
        "\n",
        "# Split the dataset based on the desired date and drop the \"id\" column\n",
        "df = df[df['timestamp'] > split_date].drop(col(\"id\"))\n",
        "\n",
        "# Recompute id column\n",
        "df = df.withColumn(\"id\", F.row_number().over(Window.orderBy(F.monotonically_increasing_id()))-1)\n",
        "# Rearranges columns\n",
        "new_columns = [\"timestamp\", \"id\"] + [col for col in df.columns if col not in [\"timestamp\", \"id\", \"next-market-price\"]] + [\"next-market-price\"]\n",
        "df = df.select(*new_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arnhM7-BDodI",
        "outputId": "cedd92ee-7d85-4f08-8ba1-b790ed3dfcc6"
      },
      "outputs": [],
      "source": [
        "if SLOW_OPERATIONS:\n",
        "  dataset_info(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY-gFc6LDodI"
      },
      "source": [
        "# Loading features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW-n42oBDodJ",
        "outputId": "b2782ed4-359b-451e-d4d1-b24dda9005da"
      },
      "outputs": [],
      "source": [
        "# Loading currency features\n",
        "with open(CURRENCY_FEATURES, \"r\") as f:\n",
        "    CURRENCY_FEATURES = json.load(f)\n",
        "print(CURRENCY_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emyww-MTDodJ",
        "outputId": "060ee913-ebb6-4d96-ef9a-df52fc973897"
      },
      "outputs": [],
      "source": [
        "# Loading currency and blockchain most correlated features\n",
        "with open(CURRENCY_MOST_CORR_FEATURES, \"r\") as f:\n",
        "    CURRENCY_MOST_CORR_FEATURES = json.load(f)\n",
        "print(CURRENCY_MOST_CORR_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNLT3xdgDodJ",
        "outputId": "cb53419b-4a76-48cf-da1c-5731220402a5"
      },
      "outputs": [],
      "source": [
        "# Loading currency and blockchain least correlated features\n",
        "with open(CURRENCY_LEAST_CORR_FEATURES, \"r\") as f:\n",
        "    CURRENCY_LEAST_CORR_FEATURES = json.load(f)\n",
        "print(CURRENCY_LEAST_CORR_FEATURES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml1T-1lIDodK"
      },
      "source": [
        "# Model train / validation\n",
        "In order to train and validate the model I'll try several approaches:\n",
        "- **Default without normalization:** Make predictions using the chosen base model\n",
        "- **Default with normalization:** Like the previous one but features are normalized\n",
        "\n",
        "At this point, the features that gave on average the most satisfactory results (for each model) are chosen and proceeded with:\n",
        "\n",
        "- **Hyperparameter tuning:** Researching the best parameters to use\n",
        "- **Cross Validation:** Validate the performance of the model with the chosen parameters\n",
        "\n",
        "If the final results are satisfactory, the model will be trained on the whole train / validation set and saved to later make predictions on the test set.\n",
        "\n",
        "For each approach the train / validation set will be split according to the chosen splitting method (in order to figure out which one works best for our problem). In this case the **Single time series split** method will be used: involves dividing the time series considering as validation set a narrow period of time and as train set everything that happened before this period, in such a way as to best benefit from the trend in the short term.\n",
        "\n",
        "![single-split.png](https://drive.google.com/uc?id=1SODyQLolK4zn9lFGnNaqnMBZrHn3OsVn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wF0XbS-DodK",
        "outputId": "5c104aaf-2068-431f-bc75-33f0da1f9932"
      },
      "outputs": [],
      "source": [
        "# Get splitting parameters based on the choosen splitting method\n",
        "splitting_info = parameters.get_splitting_params(SPLITTING_METHOD)\n",
        "splitting_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyvV-uODDodL"
      },
      "source": [
        "## Default\n",
        "The train / validation set will be splitted based on the splitting method chosen so that the model performance can be seen without any tuning by using different features (normalized and non)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RnXleAfDodL"
      },
      "source": [
        "### Without normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOL04CeODodL"
      },
      "outputs": [],
      "source": [
        "# Define model and features type\n",
        "MODEL_TYPE = \"default\"\n",
        "FEATURES_NORMALIZATION = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXtX-3CLDodL",
        "outputId": "edd9ec09-09cd-44c3-d2e2-ddbfb0654b04"
      },
      "outputs": [],
      "source": [
        "# Get default parameters\n",
        "params = parameters.get_defaults_model_params(MODEL_NAME)\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TVUAV3OPDodL",
        "outputId": "49e8ab4f-9219-4e0a-a8da-f2465a751494"
      },
      "outputs": [],
      "source": [
        "# Make predictions by using currency features\n",
        "default_train_results_currency_features, default_valid_results_currency_features, default_train_pred_currency_features, default_valid_pred_currency_features = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CURRENCY_FEATURES, CURRENCY_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zfg7eDxiDodL",
        "outputId": "3371c157-2ffe-41e6-c9ca-1389c272fff1"
      },
      "outputs": [],
      "source": [
        "default_train_results_currency_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_valid_results_currency_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "1zEUAFV8DodM",
        "outputId": "e6640c2c-17bc-49b3-f562-08e118247843"
      },
      "outputs": [],
      "source": [
        "# Make predictions by using currency and blockchain most correlated features\n",
        "default_train_results_currency_most_corr_features, default_valid_results_currency_most_corr_features, default_train_pred_currency_most_corr_features, default_valid_pred_currency_most_corr_features = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CURRENCY_MOST_CORR_FEATURES, CURRENCY_MOST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "iMvtITDaDodM",
        "outputId": "406f86e4-2bc3-4d70-e5ec-e59240c3ddb9"
      },
      "outputs": [],
      "source": [
        "default_train_results_currency_most_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_valid_results_currency_most_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "HEsXV_dyDodM",
        "outputId": "f976c817-e37e-4e31-875e-84697d339563"
      },
      "outputs": [],
      "source": [
        "# Make predictions by using currency and blockchain least correlated features\n",
        "default_train_results_currency_least_corr_features, default_valid_results_currency_least_corr_features, default_train_pred_currency_least_corr_features, default_valid_pred_currency_least_corr_features = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CURRENCY_LEAST_CORR_FEATURES, CURRENCY_LEAST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MmPHIJaPDodN",
        "outputId": "f839de4e-3395-48e2-bf4c-3f29139c2886"
      },
      "outputs": [],
      "source": [
        "default_train_results_currency_least_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_valid_results_currency_least_corr_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlDB5U0tDodN"
      },
      "source": [
        "### With normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA7gkq1yDodO"
      },
      "outputs": [],
      "source": [
        "# Define model and features type\n",
        "MODEL_TYPE = \"default_norm\"\n",
        "FEATURES_NORMALIZATION = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "vySak5zuDodO",
        "outputId": "8d1e2364-5ef5-44d1-d1fa-f6881dfd330b"
      },
      "outputs": [],
      "source": [
        "# Make predictions by using currency features\n",
        "default_norm_train_results_currency_features, default_norm_valid_results_currency_features, default_norm_train_pred_currency_features, default_norm_valid_pred_currency_features = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CURRENCY_FEATURES, CURRENCY_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2IbDCF-HDodO",
        "outputId": "9178452a-fa48-422c-a22f-60cd0463e794"
      },
      "outputs": [],
      "source": [
        "default_norm_train_results_currency_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_norm_valid_results_currency_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ENEMQd6-DodP",
        "outputId": "ca5f01ea-3f4a-4bdf-8579-aa6ccb01a3bc"
      },
      "outputs": [],
      "source": [
        "# Make predictions by using currency and blockchain most correlated features\n",
        "default_norm_train_results_currency_most_corr_features, default_norm_valid_results_currency_most_corr_features, default_norm_train_pred_currency_most_corr_features, default_norm_valid_pred_currency_most_corr_features = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CURRENCY_MOST_CORR_FEATURES, CURRENCY_MOST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-vARG4KyDodP",
        "outputId": "0fdb942f-b728-4f5a-f37e-76c99cbf2f01"
      },
      "outputs": [],
      "source": [
        "default_norm_train_results_currency_most_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_norm_valid_results_currency_most_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "iqxyr279DodU",
        "outputId": "ddbcbeb6-1b8f-4f6e-e08e-9e39b866fdcd"
      },
      "outputs": [],
      "source": [
        "# Make predictions by using currency and blockchain least correlated features\n",
        "default_norm_train_results_currency_least_corr_features, default_norm_valid_results_currency_least_corr_features, default_norm_train_pred_currency_least_corr_features, default_norm_valid_pred_currency_least_corr_features = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CURRENCY_LEAST_CORR_FEATURES, CURRENCY_LEAST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RH6Obi4iDodV",
        "outputId": "c36a1252-d6a8-43cd-a2be-958bad6202a0"
      },
      "outputs": [],
      "source": [
        "default_norm_train_results_currency_least_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_norm_valid_results_currency_least_corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtEpO2pCDodV"
      },
      "outputs": [],
      "source": [
        "# Define model information and evaluators to show\n",
        "model_info = ['Model', 'Type', 'Dataset', 'Splitting', 'Features', 'Parameters']\n",
        "evaluator_lst = ['RMSE', 'MSE', 'MAE', 'MAPE', 'R2', 'Adjusted_R2', 'Time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "fS8ToynvDodV",
        "outputId": "2942778c-d696-47e1-b6b8-8a22c0d47bfe"
      },
      "outputs": [],
      "source": [
        "# Define the results to show\n",
        "default_comparison_lst = [default_valid_results_currency_features, default_valid_results_currency_most_corr_features, default_valid_results_currency_least_corr_features, default_norm_valid_results_currency_features, default_norm_valid_results_currency_most_corr_features, default_norm_valid_results_currency_least_corr_features]\n",
        "\n",
        "# Show the comparison table\n",
        "default_comparison_lst_df = pd.concat([utilities.model_comparison(results, model_info, evaluator_lst) for results in default_comparison_lst])\n",
        "default_comparison_lst_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best default model results and predicitons\n",
        "best_default_results = default_norm_valid_results_all_features\n",
        "best_default_predictions = default_norm_valid_pred_all_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALnZJmnDodV"
      },
      "source": [
        "## Tuned\n",
        "Once the features and execution method are selected, the model will undergo hyperparameter tuning and cross validation to find the best configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL5vaO92DodW"
      },
      "outputs": [],
      "source": [
        "# Using one of the multiple splitting methods to tune the model\n",
        "SPLITTING_METHOD = \"walk_forward_splits\"\n",
        "\n",
        "# Get splitting parameters based on the choosen splitting method\n",
        "splitting_info = parameters.get_splitting_params(SPLITTING_METHOD)\n",
        "splitting_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V27ZRFNrDodW"
      },
      "source": [
        "### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu8yg9DADodW"
      },
      "outputs": [],
      "source": [
        "# Select the type of feature to be used\n",
        "MODEL_TYPE = \"hyp_tuning\"\n",
        "CHOSEN_FEATURES = ALL_FEATURES\n",
        "CHOSEN_FEATURES_LABEL = ALL_FEATURES_NAME\n",
        "FEATURES_NORMALIZATION = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVzB4IUXDodW"
      },
      "outputs": [],
      "source": [
        "# Get model grid parameters\n",
        "params = parameters.get_model_grid_params(MODEL_NAME)\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u3w6YBwDodW"
      },
      "outputs": [],
      "source": [
        "# Perform hyperparameter tuning\n",
        "hyp_res = utilities.multiple_splits(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)\n",
        "hyp_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hte_AqXpDodW"
      },
      "source": [
        "---\n",
        "Since I will use the Walking forward splitting method during this phase I compute a score for each parameter chosen by each split assigning weights based on:\n",
        "* Their frequency for each split (if the same parameters are chosen from several splits, these will have greater weight) \n",
        "* The split they belong to (the closer the split is to today's date the more weight they will have)\n",
        "* Their RMSE value for each split (the lower this is, the more weight they will have)\n",
        "\n",
        "Finally, the overall score will be calculated by putting together these weights for each parameter and the one with the best score will be the chosen parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0eRCiLbDodX"
      },
      "outputs": [],
      "source": [
        "# Show parameters score\n",
        "grouped_scores, best_params = parameters.choose_best_params(hyp_res)\n",
        "grouped_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFMoAckODodX"
      },
      "outputs": [],
      "source": [
        "# Print best parameters\n",
        "print(f\"Best parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MFSn-hsDodX"
      },
      "source": [
        "### Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtgIda2YDodX"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = \"cross_val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTnOTjNsDodX"
      },
      "outputs": [],
      "source": [
        "# Get tuned parameters\n",
        "params = parameters.get_best_model_params(best_params, MODEL_NAME)\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqWSx_k1DodX"
      },
      "outputs": [],
      "source": [
        "# Perform cross validation\n",
        "cv_train_result, cv_valid_result, cv_train_pred, cv_valid_pred = utilities.multiple_splits(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5cAqWwJDodY"
      },
      "outputs": [],
      "source": [
        "cv_train_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_valid_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hu8iqPNDodY"
      },
      "source": [
        "Let's see if the situation has improved by validating the model with the newly found parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDHsuJ-lDodY"
      },
      "outputs": [],
      "source": [
        "# Using single split method to validate the model\n",
        "SPLITTING_METHOD = \"single_split\"\n",
        "\n",
        "# Get splitting parameters based on the choosen splitting method\n",
        "splitting_info = parameters.get_splitting_params(SPLITTING_METHOD)\n",
        "splitting_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGZTR62-DodY"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = \"tuned\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__Sb_TV_DodZ"
      },
      "outputs": [],
      "source": [
        "# Validate the model with the best parameters\n",
        "tuned_train_results, tuned_valid_results, tuned_train_pred, tuned_valid_pred = utilities.single_split(df, params, splitting_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5kIvmsTDodZ"
      },
      "outputs": [],
      "source": [
        "tuned_train_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_valid_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the results to show\n",
        "tuned_comparison_lst = [cv_valid_result, tuned_valid_results]\n",
        "\n",
        "# Show the comparison table\n",
        "tuned_comparison_lst_df = pd.concat([utilities.model_comparison(results, model_info, evaluator_lst) for results in tuned_comparison_lst])\n",
        "tuned_comparison_lst_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVOLioduDodZ"
      },
      "source": [
        "## Trained\n",
        "At this point it is possible to train the final model over the entire train / validation set in order to use it in the final step, that is, to make predictions about the data contained in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kUWjf2_DodZ"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = \"final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh-R8TSoDodZ"
      },
      "outputs": [],
      "source": [
        "# Train the final model on the whole train / validation set\n",
        "final_train_results, final_model, final_train_pred = utilities.evaluate_trained_model(df, params, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_train_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkg640dRDoda"
      },
      "source": [
        "# Comparison table\n",
        "Visualization of model performance at various stages of train / validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg3h5SqADoda"
      },
      "outputs": [],
      "source": [
        "# Concatenate final results into Pandas dataset\n",
        "final_comparison_lst_df = pd.DataFrame(pd.concat([default_comparison_lst_df, tuned_comparison_lst_df, final_train_results], ignore_index=True))\n",
        "final_comparison_lst_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuf_y6_iDoda"
      },
      "source": [
        "# Model accuracy\n",
        "\n",
        "Since predicting the price accurately is very difficult let's se how good the model is at predicting whether the price will go up or down. \n",
        "\n",
        "For each row in our predictions let's consider the actual market-price, next-market-price and our predicted next-market-price (prediction).\n",
        "We compute whether the current prediction is correct (1) or not (0):\n",
        "\n",
        "$$ \n",
        "prediction\\_is\\_correct\n",
        "= \n",
        "\\begin{cases}\n",
        "0 \\text{ if [(market-price > next-market-price) and (market-price < prediction)] or [(market-price < next-market-price) and (market-price > prediction)]} \\\\\n",
        "1 \\text{ if [(market-price > next-market-price) and (market-price > prediction)] or [(market-price < next-market-price) and (market-price < prediction)]}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "After that I count the number of correct prediction:\n",
        "$$ \n",
        "correct\\_predictions\n",
        "= \n",
        "\\sum_{i=0}^{total\\_rows} prediction\\_is\\_correct\n",
        "$$\n",
        "\n",
        "Finally I compute the percentage of accuracy of the model:\n",
        "$$\n",
        "\\\\ \n",
        "accuracy \n",
        "= \n",
        "(correct\\_predictions / total\\_rows) \n",
        "* 100\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9idSt5BDodb"
      },
      "outputs": [],
      "source": [
        "# Convert the pandas dataset to a PySpark dataset\n",
        "best_default_pred_spark = spark.createDataFrame(best_default_predictions)\n",
        "validated_pred_spark = spark.createDataFrame(tuned_valid_pred)\n",
        "\n",
        "# Compute model accuracy\n",
        "default_accuracy = utilities.model_accuracy(best_default_pred_spark)\n",
        "validated_accuracy = utilities.model_accuracy(validated_pred_spark)\n",
        "\n",
        "# Shows whether features are normalised or not\n",
        "if FEATURES_NORMALIZATION:\n",
        "    NEW_CHOSEN_FEATURES_LABEL = CHOSEN_FEATURES_LABEL + \"_norm\"\n",
        "    CHOSEN_FEATURES_LABEL = NEW_CHOSEN_FEATURES_LABEL\n",
        "\n",
        "# Saving accuracy data into dataframe\n",
        "accuracy_data = {\n",
        "    'Model': MODEL_NAME,\n",
        "    'Features': CHOSEN_FEATURES_LABEL,\n",
        "    'Splitting': SPLITTING_METHOD,\n",
        "    'Accuracy (default)': default_accuracy,\n",
        "    'Accuracy (tuned)': validated_accuracy\n",
        "}\n",
        "accuracy_data_df = pd.DataFrame(accuracy_data, index=['Model'])\n",
        "\n",
        "print(f\"Percentage of correct predictions for {MODEL_NAME} with {CHOSEN_FEATURES_LABEL} and {SPLITTING_METHOD} (default): {default_accuracy:.2f}%\")\n",
        "print(f\"Percentage of correct predictions for {MODEL_NAME} with {CHOSEN_FEATURES_LABEL} and {SPLITTING_METHOD} (tuned): {validated_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate default and tuned results\n",
        "default_tuned_results = [best_default_results, tuned_valid_results]\n",
        "default_tuned_results_df = pd.concat([utilities.model_comparison(results, model_info, evaluator_lst) for results in default_tuned_results])\n",
        "default_tuned_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wTzJSBkDodb"
      },
      "source": [
        "# Saving final results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all final comparison results\n",
        "final_comparison_lst_df.to_csv(ALL_MODEL_RESULTS, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1p3h0QqDodb"
      },
      "outputs": [],
      "source": [
        "# Save relevant results (default and tuned results)\n",
        "default_tuned_results_df.to_csv(REL_MODEL_RESULTS, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uqgIqr7Dodb"
      },
      "outputs": [],
      "source": [
        "# Saving accuracy results\n",
        "accuracy_data_df.to_csv(MODEL_ACCURACY_RESULTS, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA9XYm6lDodb"
      },
      "outputs": [],
      "source": [
        "# Saving final model\n",
        "final_model.write().overwrite().save(MAIN_DIR + '/models/' + MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export notebook in html format (remember to save the notebook and change the model name)\n",
        "if LOCAL_RUNNING:\n",
        "    !jupyter nbconvert --to html 5-single-split.ipynb --output 5-single-split_{MODEL_NAME} --output-dir='./exports'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "303fa613b6f3e1efefe7bb28036e305e1021fa6bdb083a5f9fd57f9d9bbad8eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
