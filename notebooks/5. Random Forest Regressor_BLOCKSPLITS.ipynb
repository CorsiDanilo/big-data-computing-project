{"cells":[{"cell_type":"markdown","metadata":{"id":"875W83QEO5mH"},"source":["# **Bitcoin price prediction - RandomForestRegressor**\n","### Big Data Computing final project - A.Y. 2022 - 2023\n","Prof. Gabriele Tolomei\n","\n","MSc in Computer Science\n","\n","La Sapienza, University of Rome\n","\n","### Author: Corsi Danilo (1742375) - corsi.1742375@studenti.uniroma1.it\n","\n","\n","---\n","\n","\n","Description: executing the chosen model, first with default values, then by choosing the best parameters by performing hyperparameter tuning with cross validation and performance evaluation. Finally validate the tuned model and train it on the whole train /validation set"]},{"cell_type":"markdown","metadata":{"id":"Av7V741BO5mK"},"source":["# Global constants, dependencies, libraries and tools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vT2PcyRFQQL4"},"outputs":[],"source":["# Main constants\n","LOCAL_RUNNING = True\n","SLOW_OPERATIONS = True # Decide whether or not to use operations that might slow down notebook execution\n","MODEL_NAME = \"RandomForestRegressor\"\n","MAIN_DIR = \"D:/Documents/Repository/BDC/project\" if LOCAL_RUNNING else \"/content/drive\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38408,"status":"ok","timestamp":1693387219104,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"wdaOG3AOO5mM","outputId":"69dca245-1e3e-4923-fbcb-2a712cd111b2"},"outputs":[],"source":["if not LOCAL_RUNNING: \n","    # Point Colaboratory to Google Drive\n","    from google.colab import drive\n","\n","    # Define GDrive paths\n","    drive.mount(MAIN_DIR, force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6u6HVYsO5mL"},"outputs":[],"source":["# Set main dir\n","MAIN_DIR = MAIN_DIR + \"\" if LOCAL_RUNNING else \"/MyDrive/BDC/project\"\n","\n","###################\n","# --- DATASET --- #\n","###################\n","\n","# Datasets dirs\n","DATASET_OUTPUT_DIR = MAIN_DIR + \"/datasets/output\"\n","\n","# Datasets names\n","DATASET_TRAIN_VALID_NAME = \"bitcoin_blockchain_data_30min_train_valid\"\n","\n","# Datasets paths\n","DATASET_TRAIN_VALID  = DATASET_OUTPUT_DIR + \"/\" + DATASET_TRAIN_VALID_NAME + \".parquet\"\n","\n","####################\n","# --- FEATURES --- #\n","####################\n","\n","# Features dir\n","FEATURES_DIR = MAIN_DIR + \"/features\"\n","\n","# Features labels\n","FEATURES_LABEL = \"features\"\n","TARGET_LABEL = \"next-market-price\"\n","\n","# Features names\n","ALL_FEATURES_NAME = \"all_features\"\n","MOST_CORR_FEATURES_NAME = \"most_corr_features\"\n","LEAST_CORR_FEATURES_NAME = \"least_corr_features\"\n","\n","# Features paths\n","ALL_FEATURES = FEATURES_DIR + \"/\" + ALL_FEATURES_NAME + \".json\"\n","MOST_CORR_FEATURES = FEATURES_DIR + \"/\" + MOST_CORR_FEATURES_NAME + \".json\"\n","LEAST_CORR_FEATURES = FEATURES_DIR + \"/\" + LEAST_CORR_FEATURES_NAME + \".json\"\n","\n","##################\n","# --- MODELS --- #\n","##################\n","\n","# Model dir\n","MODELS_DIR = MAIN_DIR + \"/models\"\n","\n","# Model path\n","MODEL = MODELS_DIR + \"/\" + MODEL_NAME\n","\n","#####################\n","# --- UTILITIES --- #\n","#####################\n","\n","# Utilities dir\n","UTILITIES_DIR = MAIN_DIR + \"/utilities\"\n","\n","###################\n","# --- RESULTS --- #\n","###################\n","\n","# Results dir\n","RESULTS_DIR = MAIN_DIR + \"/results\"\n","\n","# Results path\n","MODEL_RESULTS  = RESULTS_DIR + \"/\" + MODEL_NAME + \".csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhIcoShFO5mN"},"outputs":[],"source":["# Suppression of warnings for better reading\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39159,"status":"ok","timestamp":1693387258261,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"h3n3XnxRO5mN","outputId":"de60d1c4-8ea2-411a-d710-477d22ff4316"},"outputs":[],"source":["if not LOCAL_RUNNING:\n","    # Install Spark and related dependencies\n","    !pip install pyspark\n","    !pip install -U -q PyDrive -qq\n","    !apt install openjdk-8-jdk-headless -qq"]},{"cell_type":"markdown","metadata":{"id":"9fgfTJIXO5mN"},"source":["# Import files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3888,"status":"ok","timestamp":1693387262147,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"GxFAJjyFO5mO","outputId":"3a067b50-c031-409e-a459-8650e4df385e"},"outputs":[],"source":["# Import my files\n","import sys\n","sys.path.append(UTILITIES_DIR)\n","\n","from imports import *\n","import utilities, parameters\n","\n","importlib.reload(utilities)\n","importlib.reload(parameters)"]},{"cell_type":"markdown","metadata":{"id":"VWHHHCqtO5mO"},"source":["# Create the pyspark session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4r5hSIXO5mO"},"outputs":[],"source":["# Create the session\n","conf = SparkConf().\\\n","                set('spark.ui.port', \"4050\").\\\n","                set('spark.executor.memory', '12G').\\\n","                set('spark.driver.memory', '12G').\\\n","                set('spark.driver.maxResultSize', '109G').\\\n","                set(\"spark.kryoserializer.buffer.max\", \"1G\").\\\n","                setAppName(\"BitcoinPricePrediction\").\\\n","                setMaster(\"local[*]\")\n","\n","# Create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"UHoseAh2O5mP"},"source":["# Loading dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEMXB6vBO5mP"},"outputs":[],"source":["# Load train / validation set into pyspark dataset objects\n","df = spark.read.load(DATASET_TRAIN_VALID,\n","                         format=\"parquet\",\n","                         sep=\",\",\n","                         inferSchema=\"true\",\n","                         header=\"true\"\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1lbKAWrO5mP"},"outputs":[],"source":["def dataset_info(dataset):\n","  # Print dataset\n","  dataset.show(3)\n","\n","  # Get the number of rows\n","  num_rows = dataset.count()\n","\n","  # Get the number of columns\n","  num_columns = len(dataset.columns)\n","\n","  # Print the shape of the dataset\n","  print(\"Shape:\", (num_rows, num_columns))\n","\n","  # Print the schema of the dataset\n","  dataset.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4840,"status":"ok","timestamp":1693387284221,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"yYDiZ_14O5mP","outputId":"b6aee141-3858-4573-ea28-2acd1982d928"},"outputs":[],"source":["if SLOW_OPERATIONS:\n","  dataset_info(df)"]},{"cell_type":"markdown","metadata":{"id":"nrFGxlwLO5mi"},"source":["# Loading features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1693387284601,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"xuKLAWnfO5mi","outputId":"4e23eae8-0b0d-4c7a-fbf5-75072e546244"},"outputs":[],"source":["# Loading all the features\n","with open(ALL_FEATURES, \"r\") as f:\n","    ALL_FEATURES = json.load(f)\n","print(ALL_FEATURES)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693387284601,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"x36W4PNlO5mi","outputId":"1e0c7445-f2bf-4cdd-ec27-776e416ab84c"},"outputs":[],"source":["# Loading the most correlated features\n","with open(MOST_CORR_FEATURES, \"r\") as f:\n","    MOST_CORR_FEATURES = json.load(f)\n","print(MOST_CORR_FEATURES)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1693387284880,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"u3VmkSxrO5mj","outputId":"6c65b161-389b-4b9e-9480-b1bfc185670e"},"outputs":[],"source":["# Loading least correlated features\n","with open(LEAST_CORR_FEATURES, \"r\") as f:\n","    LEAST_CORR_FEATURES = json.load(f)\n","print(LEAST_CORR_FEATURES)"]},{"cell_type":"markdown","metadata":{},"source":["# Model train / validation ❗\n","In order to train and validate the model, I'll try several approaches:\n","- **Simple:** Make predictions using the chosen base model\n","- **Simple with normalization:** Like the previous one but features are normalized\n","\n","At this point, the features that gave on average the most satisfactory results (for each model) are chosen and proceeded with:\n","\n","- **Hyperparameter tuning:** model validation to find the best parameters to use\n","- **Cross Validation:** validate the performance of the model with the chosen parameters\n","- **Validate final model:** validate the model with the chosen parameters\n","- **Train final model:** train the final model on the whole train / validation set to be ready to make predictions on market price"]},{"cell_type":"markdown","metadata":{"id":"phCxrDnx6EJc"},"source":["## Simple ❗\n","The train / validation set will be splitted so that the model performance can be seen without any tuning by using different features (normalized and non)"]},{"cell_type":"markdown","metadata":{"id":"1GkbQp-0O5mj"},"source":["### Simple model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5p9sE6vUo9Z"},"outputs":[],"source":["# Define model and features type\n","MODEL_TYPE = \"simple\"\n","FEATURES_NORMALIZATION = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693387284880,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"-LCrbUC7O5mj","outputId":"d872e869-127e-4d05-8a9e-4d978b27cae7"},"outputs":[],"source":["# Get default parameters\n","params = parameters.get_defaults_model_params(MODEL_NAME)\n","params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cv_info = parameters.get_cross_validation_params('multi_splits')\n","cv_info = parameters.get_cross_validation_params('block_splits')\n","# cv_info = parameters.get_cross_validation_params('walk_forward_splits')\n","cv_info"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Takes the total number of samples, the minimum number of observations, and the sliding window size as input \n","# and returns a list of tuples containing the start, split, and end positions for each walk-forward split. \n","# We then add an index column to the dataset using the monotonically_increasing_id function and calculate \n","# the total number of samples. Finally, we iterate over the generated split positions, create training and \n","# validation datasets, and train and evaluate the model on each split.\n","def walk_forward_splits_new(num, min_obser, sliding_window):\n","    split_positions = []\n","    start = 0\n","    while start + min_obser + sliding_window <= num:\n","        split_positions.append((start, start + min_obser, start + min_obser + sliding_window))\n","        start += sliding_window\n","\n","    split_position_df = pd.DataFrame(split_positions, columns=['start', 'split', 'end'])\n","\n","    return split_position_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Description: Cross validation on time series data\n","Args:\n","    dataset: The dataset which needs to be splited\n","    params: Parameters which want to test \n","    cv_info: The type of cross validation [multi_splits | block_splits]\n","    model_name: Model name selected\n","    features_normalization: Indicates whether features should be normalized (True) or not (False)\n","    features: Features to be used to make predictions\n","    features_name: Name of features used\n","    features_label: The column name of features\n","    target_label: The column name of target variable\n","Return: \n","    results_lst_df: All the splits performances in a pandas dataset\n","'''\n","def cross_validation(dataset, params, cv_info, model_name, model_type, features_normalization, features, features_name, features_label, target_label):\n","    # Select the type of features to be used\n","    dataset = utilities.select_features(dataset, features_normalization, features, features_label, target_label)\n","\n","    # Get the number of samples\n","    num = dataset.count()\n","    \n","    # Save results in a list\n","    results_lst = []\n","\n","    # Initialize an empty list to store predictions\n","    predictions_list = []  \n","\n","    # Identify the type of cross validation \n","    if cv_info['cv_type'] == 'multi_splits':\n","        split_position_df = utilities.multi_splits(num, cv_info['splits'])\n","    elif cv_info['cv_type'] == 'block_splits':\n","        split_position_df = utilities.block_splits(num, cv_info['splits'])\n","    elif cv_info['cv_type'] == 'walk_forward_splits':\n","        split_position_df = walk_forward_splits_new(num, cv_info['min_obser'], cv_info['sliding_window'])\n","\n","    for position in split_position_df.itertuples():\n","        # Get the start/split/end position based on the type of cross validation\n","        start = getattr(position, 'start')\n","        splits = getattr(position, 'split')\n","        end = getattr(position, 'end')\n","        idx  = getattr(position, 'Index')\n","        \n","        # Train / validation size\n","        train_size = splits - start\n","        valid_size = end - splits\n","\n","        # Get training data and validation data\n","        train_data = dataset.filter(dataset['id'].between(start, splits-1))\n","        valid_data = dataset.filter(dataset['id'].between(splits, end-1))\n","\n","        # Cache them\n","        train_data.cache()\n","        valid_data.cache()\n","        \n","        # All combination of params\n","        param_lst = [dict(zip(params, param)) for param in product(*params.values())]\n","\n","        for param in param_lst:\n","            # Chosen Model\n","            model = utilities.model_selection(model_name, param, features_label, target_label)\n","\n","            # Chain assembler and model in a Pipeline\n","            pipeline = Pipeline(stages=[model])\n","\n","            # Train a model and calculate running time\n","            start = time.time()\n","            pipeline_model = pipeline.fit(train_data)\n","            end = time.time()\n","\n","            # Make predictions\n","            predictions = pipeline_model.transform(valid_data).select(target_label, \"prediction\", 'timestamp')\n","            \n","            # Append predictions to the list\n","            predictions_list.append(predictions)  \n","\n","            # Compute validation error by several evaluators\n","            eval_res = utilities.model_evaluation(target_label, predictions)\n","\n","            # Use dict to store each result\n","            results = {\n","                \"Model\": model_name,\n","                \"Type\": model_type,\n","                \"Cv\": cv_info['cv_type'],\n","                \"Features\": features_name,\n","                \"Splits\": idx + 1,\n","                \"Train&Validation\": (train_size,valid_size),                \n","                \"Parameters\": list(param.values()),\n","                \"RMSE\": eval_res['rmse'],\n","                \"MSE\": eval_res['mse'],\n","                \"MAE\": eval_res['mae'],\n","                \"MAPE\": eval_res['mape'],\n","                \"R2\": eval_res['r2'],\n","                \"Adjusted_R2\": eval_res['adj_r2'],\n","                \"Time\": end - start,\n","            }\n","\n","            # Store results for each split\n","            results_lst.append(results)\n","            print(results)\n","\n","        # Release Cache\n","        train_data.unpersist()\n","        valid_data.unpersist()\n","\n","    # Transform dict to pandas dataset\n","    results_lst_df = pd.DataFrame(results_lst)\n","\n","    # Create an empty DataFrame with the same schema as the predictions dataset\n","    final_predictions = spark.createDataFrame([], schema=predictions_list[0].schema)\n","\n","    # Iterate over the list of DataFrames and union them with the merged DataFrame\n","    for pred in predictions_list:\n","        final_predictions = final_predictions.union(pred)\n","\n","    return results_lst_df, final_predictions.toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":14959,"status":"ok","timestamp":1693387299837,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"ybEwBT_GO5mj","outputId":"4aee7071-e1e3-4a7f-8cd9-ff80f862d141"},"outputs":[],"source":["# Make predictions by using all the features\n","simple_res_all, simple_pred_all = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, ALL_FEATURES, ALL_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)\n","simple_res_all"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":2099,"status":"ok","timestamp":1693387301935,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"AU4WOGaPO5mj","outputId":"e3a2a3ba-944d-4010-9ef8-07b8c90bf28f"},"outputs":[],"source":["utilities.show_results(simple_pred_all, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":8918,"status":"ok","timestamp":1693387310850,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"bXdI7FbtO5mk","outputId":"0812b67e-1649-483c-99d6-7fdd27fae994"},"outputs":[],"source":["# Make predictions by using the most correlated features\n","simple_res_most_corr, simple_pred_most_corr = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, MOST_CORR_FEATURES, MOST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)\n","simple_res_most_corr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":1085,"status":"ok","timestamp":1693387311933,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"rgspchOgO5mk","outputId":"8a67d422-d40b-462b-f6e1-373a792221ab"},"outputs":[],"source":["utilities.show_results(simple_pred_most_corr, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":5083,"status":"ok","timestamp":1693387317013,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"tJ-z2gRAO5mk","outputId":"225141ce-49d8-40f4-946e-733fb266d10f"},"outputs":[],"source":["# Make predictions by using the least correlated features\n","simple_res_least_corr, simple_pred_least_corr = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, LEAST_CORR_FEATURES, LEAST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)\n","simple_res_least_corr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":1169,"status":"ok","timestamp":1693387318180,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"1dHI7hifO5mk","outputId":"d3464345-21e5-41f9-8457-8faa8b73b355"},"outputs":[],"source":["utilities.show_results(simple_pred_least_corr, MODEL_NAME)"]},{"cell_type":"markdown","metadata":{"id":"hkVljtjRO5ml"},"source":["### Simple model (with normalization)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAkG38iFUlsg"},"outputs":[],"source":["# Define model and features type\n","MODEL_TYPE = \"simple_norm\"\n","FEATURES_NORMALIZATION = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":8769,"status":"ok","timestamp":1693387326947,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"RU3wjXMKO5ml","outputId":"a7e9d955-bdb7-4780-ba1b-dabdf9eb305a"},"outputs":[],"source":["# Valid performances with all the features\n","simple_norm_res_all, simple_norm_pred_all = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, ALL_FEATURES, ALL_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)\n","simple_norm_res_all"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":984,"status":"ok","timestamp":1693387327929,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"IT6sFM5HO5ml","outputId":"cb8d6e87-aafc-4e85-c2df-2dfd1e7c542b"},"outputs":[],"source":["utilities.show_results(simple_norm_pred_all, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":5021,"status":"ok","timestamp":1693387332948,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"d13xyXqNO5ml","outputId":"62b7059d-013e-43f0-f25b-27c62d6d2154"},"outputs":[],"source":["# Make predictions by using the most the features\n","simple_norm_res_most_corr, simple_norm_pred_most_corr = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, MOST_CORR_FEATURES, MOST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)\n","simple_norm_res_most_corr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1693387333907,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"flWSz8RnO5ml","outputId":"3dbbcf7b-53eb-4899-8aa1-0a9cc7db68a2"},"outputs":[],"source":["utilities.show_results(simple_norm_pred_most_corr, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":6984,"status":"ok","timestamp":1693387340889,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"kJUVfeXkO5ml","outputId":"6332213b-7d5a-4d7c-9d2f-7a78706b1e15"},"outputs":[],"source":["# Make predictions by using the least the features\n","simple_norm_res_least_corr, simple_norm_pred_least_corr = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, LEAST_CORR_FEATURES, LEAST_CORR_FEATURES_NAME, FEATURES_LABEL, TARGET_LABEL)\n","simple_norm_res_least_corr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":835,"status":"ok","timestamp":1693387341722,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"Q_-5zkTOO5ml","outputId":"1b6c47ff-32a4-48da-fb44-4a5eb04422ee"},"outputs":[],"source":["utilities.show_results(simple_norm_pred_least_corr, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1693387391701,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"QDacpgPDv8Hw","outputId":"cdc326c7-61b0-4482-946f-785a2158eed9"},"outputs":[],"source":["# Define model information and evaluators to show\n","model_info = ['Model', 'Type', 'Cv', 'Features', 'Parameters']\n","evaluator_lst = ['RMSE', 'MSE', 'MAE', 'MAPE', 'R2', 'Adjusted_R2', 'Time']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the results to show\n","simple_comparison_lst = [simple_res_all, simple_res_most_corr, simple_res_least_corr,simple_norm_res_all, simple_norm_res_most_corr, simple_norm_res_least_corr]\n","\n","# Show the comparison table\n","simple_comparison_lst_df = pd.concat([utilities.model_comparison(results, model_info, evaluator_lst) for results in simple_comparison_lst])\n","simple_comparison_lst_df"]},{"cell_type":"markdown","metadata":{"id":"dMrqIYJV6HdF"},"source":["## Tuned ❗\n","Once the features and execution method are selected, the model will undergo hyperparameter tuning and cross validation to find the best configuration."]},{"cell_type":"markdown","metadata":{"id":"sCQV4CQcO5mm"},"source":["### Hyperparameter tuning with cross validation\n","The train / validation set is divided based on a portion list which will split the dataset into several splits.\n","\n","For each split, all combinations of the model parameters are tested and those that return a lower RMSE are considered.\n","\n","Using the previously selected parameters, the model undergoes two types of cross validation:"]},{"cell_type":"markdown","metadata":{},"source":["**Multiple splits**\n","\n","The idea is to divide the dataset into two folds at each iteration on condition that the validation set is always ahead of the training set. This way dependence is respected."]},{"cell_type":"markdown","metadata":{},"source":["**Blocked time series**\n","\n","It works by adding margins at two positions. The first is between the training and validation folds in order to prevent the model from observing lag values which are used twice, once as a regressor and another as a response. The second is between the folds used at each iteration in order to prevent the model from memorizing patterns from an iteration to the next."]},{"cell_type":"markdown","metadata":{},"source":["**Walk forward time series**\n","\n","The basic idea behind walk-forward validation is to iteratively train and evaluate the model using a sliding window approach. Here's how it works:\n","*  Split the time series data into a training set and a test set. The training set contains the initial portion of the data, while the test set contains the subsequent portion.\n","* Train the model on the training set and make predictions on the test set.\n","Evaluate the performance of the model on the test set using appropriate evaluation metrics such as mean squared error (MSE), root mean squared error (RMSE), or mean absolute error (MAE).\n","* Move the sliding window forward by one step, incorporating the next data point into the training set and shifting the test set accordingly.\n","* Repeat steps 2-4 until the entire time series has been used for testing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvBZZIedO5mm"},"outputs":[],"source":["# From now on, only selected and normalized features will be considered\n","MODEL_TYPE = \"hyp_tuning\"\n","CHOSEN_FEATURES = ALL_FEATURES\n","CHOSEN_FEATURES_LABEL = ALL_FEATURES_NAME\n","FEATURES_NORMALIZATION = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693387481395,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"Sep_LjlgO5mm","outputId":"0794eb42-2164-4e12-9cde-551b8964c183"},"outputs":[],"source":["# Get model grid parameters\n","params = parameters.get_model_grid_params(MODEL_NAME)\n","params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Description: Cross validation on time series data\n","Args:\n","    dataset: The dataset which needs to be splited\n","    params: Parameters which want to test \n","    cv_info: The type of cross validation [multi_splits | block_splits]\n","    model_name: Model name selected\n","    features_normalization: Indicates whether features should be normalized (True) or not (False)\n","    features: Features to be used to make predictions\n","    features_name: Name of features used\n","    features_label: The column name of features\n","    target_label: The column name of target variable\n","Return: \n","    results_lst_df: All the splits performances in a pandas dataset\n","'''\n","def hyperparameter_tuning(dataset, params, cv_info, model_name, model_type, features_normalization, features, features_name, features_label, target_label):\n","    # Select the type of features to be used\n","    dataset = utilities.select_features(dataset, features_normalization, features, features_label, target_label)\n","\n","    best_split_result = []\n","\n","    # Get the number of samples\n","    num = dataset.count()\n","\n","    # Identify the type of cross validation \n","    if cv_info['cv_type'] == 'multi_splits':\n","        split_position_df = utilities.multi_splits(num, cv_info['splits'])\n","    elif cv_info['cv_type'] == 'block_splits':\n","        split_position_df = utilities.block_splits(num, cv_info['splits'])\n","    elif cv_info['cv_type'] == 'walk_forward_splits':\n","        split_position_df = walk_forward_splits_new(num, cv_info['min_obser'], cv_info['sliding_window'])\n","\n","    for position in split_position_df.itertuples():\n","        best_result = {\"RMSE\": float('inf')}\n","\n","        # Get the start/split/end position based on the type of cross validation\n","        start = getattr(position, 'start')\n","        splits = getattr(position, 'split')\n","        end = getattr(position, 'end')\n","        idx  = getattr(position, 'Index')\n","        \n","        # Train / validation size\n","        train_size = splits - start\n","        valid_size = end - splits\n","\n","        # Get training data and validation data\n","        train_data = dataset.filter(dataset['id'].between(start, splits-1))\n","        valid_data = dataset.filter(dataset['id'].between(splits, end-1))\n","\n","        # Cache them\n","        train_data.cache()\n","        valid_data.cache()\n","\n","        # All combination of params\n","        param_lst = [dict(zip(params, param)) for param in product(*params.values())]\n","\n","        for param in param_lst:\n","            # Chosen Model\n","            model = utilities.model_selection(model_name, param, features_label, target_label)\n","\n","            # Chain assembler and model in a Pipeline\n","            pipeline = Pipeline(stages=[model])\n","\n","            # Train a model and calculate running time\n","            start = time.time()\n","            pipeline_model = pipeline.fit(train_data)\n","            end = time.time()\n","\n","            # Make predictions\n","            predictions = pipeline_model.transform(valid_data).select(target_label, \"prediction\", 'timestamp')\n","\n","            # Compute validation error by several evaluators\n","            eval_res = utilities.model_evaluation(target_label, predictions)\n","\n","            # Use dict to store each result\n","            results = {\n","                \"Model\": model_name,\n","                \"Type\": model_type,\n","                \"Cv\": cv_info['cv_type'],\n","                \"Features\": features_name,\n","                \"Splits\": idx + 1,\n","                \"Train&Validation\": (train_size,valid_size),                \n","                \"Parameters\": list(param.values()),\n","                \"RMSE\": eval_res['rmse'],\n","                \"MSE\": eval_res['mse'],\n","                \"MAE\": eval_res['mae'],\n","                \"MAPE\": eval_res['mape'],\n","                \"R2\": eval_res['r2'],\n","                \"Adjusted_R2\": eval_res['adj_r2'],\n","                \"Time\": end - start,\n","            }\n","            # Store the result with the lowest RMSE and the associated parameters\n","            if results['RMSE'] < best_result['RMSE']:\n","                best_result = results\n","\n","        # Release Cache\n","        train_data.unpersist()\n","        valid_data.unpersist()\n","\n","        best_split_result.append(best_result) \n","        print(best_result)\n","\n","    # Transform dict to pandas dataset\n","    best_split_result_df = pd.DataFrame(best_split_result)\n","\n","    return best_split_result_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":361553,"status":"ok","timestamp":1693387842946,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"K9wastyWO5mp","outputId":"69d50348-441e-4f70-d837-7687812411cd"},"outputs":[],"source":["# Perform hyperparameter tuning\n","hyp_res = hyperparameter_tuning(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)\n","hyp_res"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Count the occurrences of each value in the Parameters column\n","counts = hyp_res[\"Parameters\"].value_counts()\n","\n","# Display the counts\n","print(counts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MODEL_TYPE = \"cross_val\""]},{"cell_type":"markdown","metadata":{},"source":["## [TO DELETE] Just for testing❗"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_best_model_params(model_name):\n","    if (model_name == 'LinearRegression'):\n","        params = {\n","            'maxIter' : [5],\n","            'regParam' : [0.2],\n","            'elasticNetParam' : [0.0]\n","        }   \n","    if (model_name == 'GeneralizedLinearRegression'):\n","        params = {\n","            'maxIter' : [5],\n","            'regParam' : [0.2],\n","            'family': ['gaussian'],\n","            'link': ['log']\n","        }\n","    elif (model_name == 'RandomForestRegressor'):\n","        params = {\n","            'numTrees' : [3],\n","            'maxDepth' : [10],\n","            'seed' : [42]\n","            }\n","    elif (model_name == 'GBTRegressor'):\n","        params = {\n","            'maxIter' : [30],\n","            'maxDepth' : [3],\n","            'stepSize': [0.4],\n","            'seed' : [42]\n","        }\n","        \n","    return params"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693387865133,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"ecsTsb-hO5mp","outputId":"e730ac17-f695-44d0-e9ee-c8436af1c0c1"},"outputs":[],"source":["# Get tuned parameters\n","params = get_best_model_params(MODEL_NAME)\n","params"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":13826,"status":"ok","timestamp":1693387878957,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"u-FdKsGKO5mq","outputId":"33823374-bec3-4194-a6a6-b1d37b61c4f2"},"outputs":[],"source":["# Perform cross validation\n","cv_res, cv_pred = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)\n","cv_res"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["utilities.show_results(cv_pred, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the results to show\n","tuned_comparison_lst = [cv_res]\n","\n","# Show the comparison table\n","tuned_comparison_lst_df = pd.concat([utilities.model_comparison(results, model_info, evaluator_lst) for results in tuned_comparison_lst])\n","tuned_comparison_lst_df"]},{"cell_type":"markdown","metadata":{"id":"LiGZ1yAf6NgS"},"source":["## Final ❗\n","Finally, the configuration found will be validated and then the model will be trained one last time on the entire train / validation set, ready to make predictions."]},{"cell_type":"markdown","metadata":{"id":"AZEiSHU8Rk6G"},"source":["### Validate final model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zIkOfm1UtEe"},"outputs":[],"source":["MODEL_TYPE = \"final_validated\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":3566,"status":"ok","timestamp":1693387957931,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"MncJLfCNRKvK","outputId":"e200f07c-b54d-45ee-bf65-dc01732ca2d4"},"outputs":[],"source":["# Performances on validated final model\n","final_valid_res, final_valid_pred = cross_validation(df, params, cv_info, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)\n","final_valid_res"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":863,"status":"ok","timestamp":1693387958791,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"_1RmUhl3SbWx","outputId":"c1966069-b403-4659-b4ba-2159901375ea"},"outputs":[],"source":["utilities.show_results(final_valid_pred, MODEL_NAME)"]},{"cell_type":"markdown","metadata":{"id":"73yEuOR3O5mq"},"source":["### Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMK0n1FGc7mF"},"outputs":[],"source":["MODEL_TYPE = \"final_trained\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Description: Cross validation on time series data\n","Args:\n","    dataset: The dataset which needs to be splited\n","    params: Parameters which want to test \n","    model_name: Model name selected\n","    model_type: Model type [simple | simple_norm | hyp_tuning | final_validated | final_trained]\n","    features_normalization: Indicates whether features should be normalized (True) or not (False)\n","    features: Features to be used to make predictions\n","    features_name: Name of features used\n","    features_label: The column name of features\n","    target_label: The column name of target variable\n","Return: \n","    results_df: Results obtained from the evaluation\n","    pipeline_model: Final trained model\n","    predictions: Predictions obtained from the model\n","'''\n","def evaluate_trained_model(dataset, params, model_name, model_type, features_normalization, features, features_name, features_label, target_label):    \n","    # Select the type of features to be used\n","    dataset = utilities.select_features(dataset, features_normalization, features, features_label, target_label)\n","  \n","    # All combination of params\n","    param_lst = [dict(zip(params, param)) for param in product(*params.values())]\n","    \n","    for param in param_lst:\n","        # Chosen Model\n","        model = utilities.model_selection(model_name, param, features_label, target_label)\n","        \n","        # Chain assembler and model in a Pipeline\n","        pipeline = Pipeline(stages=[model])\n","\n","        # Train a model and calculate running time\n","        start = time.time()\n","        pipeline_model = pipeline.fit(dataset)\n","        end = time.time()\n","\n","        # Make predictions\n","        predictions = pipeline_model.transform(dataset).select(target_label, \"prediction\", 'timestamp')\n","\n","        # Compute validation error by several evaluators\n","        eval_res = utilities.model_evaluation(target_label, predictions)\n","\n","        # Use dict to store each result\n","        results = {\n","            \"Model\": model_name,\n","            \"Type\": model_type,\n","            \"Cv\": \"none\",\n","            \"Features\": features_name,\n","            \"Parameters\": [list(param.values())],\n","            \"RMSE\": eval_res['rmse'],\n","            \"MSE\": eval_res['mse'],\n","            \"MAE\": eval_res['mae'],\n","            \"MAPE\": eval_res['mape'],\n","            \"R2\": eval_res['r2'],\n","            \"Adjusted_R2\": eval_res['adj_r2'],\n","            \"Time\": end - start,\n","        }\n","\n","    # Transform dict to pandas dataset\n","    results_df = pd.DataFrame(results)\n","        \n","    return results_df, pipeline_model, predictions.toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":10638,"status":"ok","timestamp":1693387969427,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"Nh7BlZ5Fc-TF","outputId":"8d071181-2a03-44df-f171-453dd3d5b187"},"outputs":[],"source":["# Train the model on the whole train / validation set\n","final_train_res, final_train_model, final_train_pred = evaluate_trained_model(df, params, MODEL_NAME, MODEL_TYPE, FEATURES_NORMALIZATION, CHOSEN_FEATURES, CHOSEN_FEATURES_LABEL, FEATURES_LABEL, TARGET_LABEL)\n","final_train_res"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1jEG7n24hDOkQ3jLCcY5WeXXG3O5uoOTS"},"executionInfo":{"elapsed":10318,"status":"ok","timestamp":1693387979743,"user":{"displayName":"Danilo Corsi","userId":"10800270661719155402"},"user_tz":-120},"id":"ocJzN3zbc-ix","outputId":"0a61e3b1-7f48-4d71-ff66-c31ccda59527"},"outputs":[],"source":["utilities.show_results(final_train_pred, MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the results to show\n","valid_comparison_lst = [final_valid_res, final_train_res]\n","\n","# Show the comparison table\n","valid_comparison_lst_df = pd.concat([utilities.model_comparison(results, model_info, evaluator_lst) for results in valid_comparison_lst])\n","valid_comparison_lst_df"]},{"cell_type":"markdown","metadata":{"id":"ARKKMvqYO5mq"},"source":["# Comparison table\n","Visualization of model performance at various stages of train / validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Concatenate simple results into Pandas Dataframe\n","final_comparison_lst_df = pd.DataFrame(pd.concat([simple_comparison_lst_df, tuned_comparison_lst_df , valid_comparison_lst_df], ignore_index=True))\n","final_comparison_lst_df"]},{"cell_type":"markdown","metadata":{"id":"ESSGFrtlO5mr"},"source":["# Saving trained model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NTiO3elUiDo"},"outputs":[],"source":["# Saving final model results\n","final_comparison_lst_df.to_csv(MODEL_RESULTS, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzzYNCDoO5mr"},"outputs":[],"source":["# Save the trained model\n","final_train_model.write().overwrite().save(MODEL)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"303fa613b6f3e1efefe7bb28036e305e1021fa6bdb083a5f9fd57f9d9bbad8eb"}}},"nbformat":4,"nbformat_minor":0}
