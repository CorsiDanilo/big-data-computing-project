{"cells":[{"cell_type":"markdown","metadata":{"id":"oqwl6Bf0Lv9D"},"source":["# **Bitcoin price prediction with PySpark - Feature Engineering**\n","## Big Data Computing final project - A.Y. 2022 - 2023\n","Prof. Gabriele Tolomei\n","\n","MSc in Computer Science\n","\n","La Sapienza, University of Rome\n","\n","### Author: Corsi Danilo (1742375) - corsi.1742375@studenti.uniroma1.it\n","\n","\n","---\n","\n","\n","Description: adding useful features regardings the price of Bitcoin, visualizing data and performing feature selection\n"]},{"cell_type":"markdown","metadata":{"id":"FIbEK2pDLv9x"},"source":["# Global constants, dependencies, libraries and tools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUpNH3eIQPR4"},"outputs":[],"source":["# Main constants\n","LOCAL_RUNNING = True\n","SLOW_OPERATIONS = True # Decide whether or not to use operations that might slow down notebook execution\n","MAIN_DIR = \"D:/Documents/Repository/BDC/project\" if LOCAL_RUNNING else \"/content/drive\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKk35k0MLv9y"},"outputs":[],"source":["if not LOCAL_RUNNING: \n","    # Point Colaboratory to Google Drive\n","    from google.colab import drive\n","\n","    # Define GDrive paths\n","    drive.mount(MAIN_DIR, force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQ8YvlaZLv9x"},"outputs":[],"source":["# Set main dir\n","MAIN_DIR = MAIN_DIR + \"\" if LOCAL_RUNNING else \"/MyDrive/BDC/project\"\n","\n","###################\n","# --- DATASET --- #\n","###################\n","\n","# Datasets dirs\n","DATASET_RAW_DIR = MAIN_DIR + \"/datasets/raw\"\n","DATASET_OUTPUT_DIR = MAIN_DIR + \"/datasets/output\"\n","DATASET_TEMP_DIR = MAIN_DIR + \"/datasets/temp\"\n","\n","# Datasets names\n","DATASET_NAME = \"bitcoin_blockchain_data_30min\"\n","\n","# Datasets paths\n","DATASET_RAW = DATASET_RAW_DIR + \"/\" + DATASET_NAME + \".parquet\"\n","\n","####################\n","# --- FEATURES --- #\n","####################\n","\n","# Features dir\n","FEATURES_DIR = MAIN_DIR + \"/features\"\n","\n","# Features names\n","FEATURES_CORRELATION_NAME = \"features_correlation\"\n","ALL_FEATURES_NAME = \"all_features\"\n","MOST_CORR_FEATURES_NAME = \"most_corr_features\"\n","LEAST_CORR_FEATURES_NAME = \"least_corr_features\"\n","\n","# Features paths\n","FEATURES_CORRELATION = FEATURES_DIR + \"/\" + FEATURES_CORRELATION_NAME + \".json\"\n","ALL_FEATURES = FEATURES_DIR + \"/\" + ALL_FEATURES_NAME + \".json\"\n","MOST_CORR_FEATURES = FEATURES_DIR + \"/\" + MOST_CORR_FEATURES_NAME + \".json\"\n","LEAST_CORR_FEATURES = FEATURES_DIR + \"/\" + LEAST_CORR_FEATURES_NAME + \".json\"\n","\n","#####################\n","# --- UTILITIES --- #\n","#####################\n","\n","# Utilities dir\n","UTILITIES_DIR = MAIN_DIR + \"/utilities\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvKa3zyWLv9y"},"outputs":[],"source":["# Suppression of warnings for better reading\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sifbION-Lv9y"},"outputs":[],"source":["if not LOCAL_RUNNING:\n","    # Install Spark and related dependencies\n","    !pip install pyspark\n","    !pip install -U -q PyDrive -qq\n","    !apt install openjdk-8-jdk-headless -qq"]},{"cell_type":"markdown","metadata":{"id":"jeP_41EsLv9y"},"source":["# Import files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5O0SVFUzLv9y"},"outputs":[],"source":["# Import my files\n","import sys\n","sys.path.append(UTILITIES_DIR)\n","\n","from imports import *"]},{"cell_type":"markdown","metadata":{"id":"YUI9DnQVLv9z"},"source":["# Create the pyspark session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLwcEWvYLv9z"},"outputs":[],"source":["# Create the session\n","conf = SparkConf().\\\n","                set('spark.ui.port', \"4050\").\\\n","                set('spark.executor.memory', '12G').\\\n","                set('spark.driver.memory', '12G').\\\n","                set('spark.driver.maxResultSize', '109G').\\\n","                set(\"spark.kryoserializer.buffer.max\", \"1G\").\\\n","                setAppName(\"BitcoinPricePrediction\").\\\n","                setMaster(\"local[*]\")\n","\n","# Create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"F7IjRUGdLv9z"},"source":["# Loading dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugtTXvpBLv9z"},"outputs":[],"source":["# Load datasets into pyspark dataset objects\n","df = spark.read.load(DATASET_RAW,\n","                         format=\"parquet\",\n","                         sep=\",\",\n","                         inferSchema=\"true\",\n","                         header=\"true\"\n","                    ) \\\n","                     .withColumn(\"id\", F.row_number().over(Window.orderBy(F.monotonically_increasing_id()))-1) # Adding \"id\" column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s76xwenILv9z"},"outputs":[],"source":["def dataset_info(dataset):\n","  # Print dataset\n","  dataset.show(3)\n","\n","  # Get the number of rows\n","  num_rows = dataset.count()\n","\n","  # Get the number of columns\n","  num_columns = len(dataset.columns)\n","\n","  # Print the shape of the dataset\n","  print(\"Shape:\", (num_rows, num_columns))\n","\n","  # Print the schema of the dataset\n","  dataset.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkviD2q8Lv9z"},"outputs":[],"source":["if SLOW_OPERATIONS:\n","  dataset_info(df)"]},{"cell_type":"markdown","metadata":{"id":"h1v6rsUjLv9z"},"source":["# Adding useful features\n","Here I am going to add some features that could help us predict the Bitcoin price:\n","\n","*   **Next market price:** represents the price of Bitcoin for the next day (this will be the target variable on which to make predictions)\n","*   **Rate of change:** indicator that measures the percentage of price changes over a period of time, allows investors to spot security momentum and other trends\n","*   **Simple Moving Averages:** indicators that calculate the average price over a specified number of days. They are commonly used by traders to identify trends and potential buy or sell signals\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WML0CKelLv9z"},"outputs":[],"source":["# Creation of a new dataset for the new features\n","new_features_df = df.select(\"timestamp\", \"id\", \"market-price\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7j4GFmpHLv9z"},"outputs":[],"source":["# Adding 'tomorrow-market-price' column\n","new_features_df = new_features_df.withColumn(\"next-market-price\", F.lag(\"market-price\", offset=-1) \\\n","        .over(Window.orderBy(\"id\"))) \\\n","        .dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XLttgNKLv90"},"outputs":[],"source":["# Adding \"rate-of-change\" column\n","new_features_df = new_features_df.withColumn(\"rate-of-change\", (F.col(\"next-market-price\") / F.col(\"market-price\") - 1) * 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6MPud1wLv90"},"outputs":[],"source":["def simple_moving_average(dataset, period, days, col=\"next-market-price\", orderby=\"id\"):\n","    dataset = dataset.withColumn(f\"sma-{days}-days\", F.avg(col) \\\n","          .over(Window.orderBy(orderby) \\\n","          .rowsBetween(-period,0)))\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OBOZbvILv90"},"outputs":[],"source":["# Moving averages days (5/7/10/20/50/100)\n","MA5 = 60 * 24 * 5\n","MA7 = 60 * 24 * 7\n","MA10 = 60 * 24 * 10\n","MA20 = 60 * 24 * 20\n","MA50 = 60 * 24 * 50\n","MA100 = 60 * 24 * 100\n","\n","# Computing the SMA\n","new_features_df = simple_moving_average(new_features_df, MA5, 5)\n","new_features_df = simple_moving_average(new_features_df, MA7, 7)\n","new_features_df = simple_moving_average(new_features_df, MA10, 10)\n","new_features_df = simple_moving_average(new_features_df, MA20, 20)\n","new_features_df = simple_moving_average(new_features_df, MA50, 50)\n","new_features_df = simple_moving_average(new_features_df, MA100, 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"krKDYR1yLv90"},"outputs":[],"source":["# Drop \"market-price\" column\n","new_features_df = new_features_df.drop(\"market-price\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3exSIGOLv90"},"outputs":[],"source":["if SLOW_OPERATIONS:\n","  dataset_info(new_features_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pL_5JLHyLv90"},"outputs":[],"source":["# Merge original dataset with the one with the new features\n","merged_df = df.join(new_features_df, on=['timestamp','id'], how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q74GqOn_Lv90"},"outputs":[],"source":["# Rearranges  columns\n","new_columns = [\"timestamp\", \"id\"] + [col for col in merged_df.columns if col not in [\"timestamp\", \"id\", \"next-market-price\"]] + [\"next-market-price\"]\n","merged_df = merged_df.select(*new_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9vp9SeaSaCg"},"outputs":[],"source":["# Set the \"timestamp\" column as the index of the Pandas dataset\n","merged_df.toPandas().set_index(\"timestamp\", inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d39yWzsbLv90"},"outputs":[],"source":["if SLOW_OPERATIONS:\n","  dataset_info(merged_df)"]},{"cell_type":"markdown","metadata":{"id":"wxb4eZExLv91"},"source":["# Splitting dataset\n","Here we are going to split the dataset into two sets:\n","* **Train / Validation set:** will be used to train the models and validate the performances\n","* **Test set:** will be used to perform price prediction on never-before-seen data (the last 3 months of the original dataset will be used)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5TAxfkk-v8c"},"outputs":[],"source":["# Retrieve the last timestamp value\n","last_value = merged_df.agg(last(\"timestamp\")).collect()[0][0]\n","\n","# Subtract three month from the last timestamp value\n","split_date = last_value - relativedelta(months=3)\n","\n","# Split the dataset based on the desired date\n","train_valid_df = merged_df[merged_df['timestamp'] <= split_date]\n","test_df = merged_df[merged_df['timestamp'] > split_date]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoN-4kCaLv91"},"outputs":[],"source":["def data_visualization(train_valid, test):\n","  trace1 = go.Scatter(\n","      x = train_valid['timestamp'],\n","      y = train_valid[\"market-price\"].astype(float),\n","      mode = 'lines',\n","      name = \"Train / Validation set\"\n","  )\n","\n","  trace2 = go.Scatter(\n","      x = test['timestamp'],\n","      y = test['market-price'].astype(float),\n","      mode = 'lines',\n","      name = \"Test set\"\n","  )\n","\n","  layout = dict(\n","      title=\"Train / Validation and Test sets\",\n","      xaxis=dict(\n","          rangeselector=dict(\n","              buttons=list([\n","                  # Change the count to desired amount of months.\n","                  dict(count=1,\n","                      label='1m',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=6,\n","                      label='6m',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=12,\n","                      label='1y',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=36,\n","                      label='3y',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(step='all')\n","              ])\n","          ),\n","          rangeslider=dict(\n","              visible = True\n","          ),\n","          type='date'\n","      )\n","  )\n","\n","  data = [trace1, trace2]\n","  fig = dict(data=data, layout=layout)\n","  iplot(fig, filename = \"Train / Validation and Test sets\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZ_OPmiwLv91"},"outputs":[],"source":["data_visualization(train_valid_df.toPandas(), test_df.toPandas())"]},{"cell_type":"markdown","metadata":{"id":"pO07pajqLv91"},"source":["# Saving datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0s5qokVLv91"},"outputs":[],"source":["def output(dataset, ds_type):\n","  dataset.write.parquet(DATASET_TEMP_DIR, mode='overwrite')\n","\n","  while True:\n","      parquet_files = glob.glob(os.path.join(DATASET_TEMP_DIR, \"part*.parquet\"))\n","      if len(parquet_files) > 0:\n","          # .parquet file found!\n","          file_path = parquet_files[0]\n","          break\n","      else:\n","          print(\".parquet file not found. I'll try again after 1 second...\")\n","          time.sleep(1)\n","\n","  print(\".parquet file found:\", file_path)\n","\n","  new_file_path = DATASET_OUTPUT_DIR + \"/\" + DATASET_NAME + \"_\" + ds_type +\".parquet\"\n","\n","  # Rename and move the file\n","  shutil.move(file_path, new_file_path)\n","\n","  print(\"File renamed and moved successfully!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ss2HR4JpLv91"},"outputs":[],"source":["# Save the train / validation set\n","output(train_valid_df, \"train_valid\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtPmzkfwLv96"},"outputs":[],"source":["# Save the test set\n","output(test_df, \"test\")"]},{"cell_type":"markdown","metadata":{"id":"dbFTB-2aLv96"},"source":["# Data visualization\n","\n","Here we are going to display the features taken under consideration according to their categories."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ui5CtB0sLv96"},"outputs":[],"source":["# Convert the PySpark dataset into Pandas\n","merged_df_pd = merged_df.toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcnp_SJNLv96"},"outputs":[],"source":["# List of features according to categories\n","currency_statistics = {'Market price (USD)':'market-price', 'Market cap (USD)':'market-cap', 'N. total bitcoins':'total-bitcoins', 'Trade volume (USD)':'trade-volume'}\n","block_details = {'Blocks size (MB)':'blocks-size', 'Avg. block size (MB)':'avg-block-size', 'N. total transactions':'n-transactions-total', 'N. transactions per block':'n-transactions-per-block'}\n","mining_information = {'Hash rate (TH/s)':'hash-rate', 'Difficulty (T)':'difficulty', 'Miners revenue (USD)':'miners-revenue', 'Transaction fees (USD)':'transaction-fees-usd'}\n","network_activity = {\"N. unique addresses\":'n-unique-addresses', 'N. transactions':'n-transactions', 'Estimated transaction volume (USD)':'estimated-transaction-volume-usd'}\n","additional_features = {\"Rate of change (%)\":\"rate-of-change\", \"Simple moving avg. (5d)\":\"sma-5-days\", \"Simple moving avg. (7d)\":\"sma-7-days\", \"Simple moving avg. (10d)\":\"sma-10-days\", \"Simple moving avg. (20d)\":\"sma-20-days\", \"Simple moving avg. (50d)\":\"sma-50-days\", \"Simple moving avg. (100d)\":\"sma-100-days\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cEafWckLv96"},"outputs":[],"source":["def data_visualization(dataset, key, value):\n","  trace = go.Scatter(\n","      x = dataset['timestamp'],\n","      y = dataset[value].astype(float),\n","      mode = 'lines',\n","      name = key\n","  )\n","\n","  layout = dict(\n","      title=key,\n","      xaxis=dict(\n","          rangeselector=dict(\n","              buttons=list([\n","                  # Change the count to desired amount of months.\n","                  dict(count=1,\n","                      label='1m',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=6,\n","                      label='6m',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=12,\n","                      label='1y',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=36,\n","                      label='3y',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(step='all')\n","              ])\n","          ),\n","          rangeslider=dict(\n","              visible = True\n","          ),\n","          type='date'\n","      )\n","  )\n","\n","  data = [trace]\n","  fig = dict(data=data, layout=layout)\n","  iplot(fig, filename = \"Data visualization with rangeslider\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeBnhpcSLv98"},"outputs":[],"source":["# Currency Statistics\n","if SLOW_OPERATIONS:\n","  for key, value in currency_statistics.items():\n","    data_visualization(merged_df_pd, key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9PPFCl9Lv98"},"outputs":[],"source":["# Block Details\n","if SLOW_OPERATIONS:\n","  for key, value in block_details.items():\n","    data_visualization(merged_df_pd, key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMJYU9RGLv98"},"outputs":[],"source":["# Mining Information\n","if SLOW_OPERATIONS:\n","  for key, value in mining_information.items():\n","    data_visualization(merged_df_pd, key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb-RqdrfLv98"},"outputs":[],"source":["# Network Activity\n","if SLOW_OPERATIONS:\n","  for key, value in network_activity.items():\n","    data_visualization(merged_df_pd, key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smotu8fBLv98"},"outputs":[],"source":["# Additional Features: Rate of change\n","if SLOW_OPERATIONS:\n","  first_pair = next(iter(additional_features.items()))\n","  data_visualization(merged_df_pd, first_pair[0], first_pair[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kA5QQADhLv98"},"outputs":[],"source":["def sma_visualization(dataset, features, title):\n","  trace1 = go.Scatter(\n","      x = dataset['timestamp'],\n","      y = dataset[\"market-price\"].astype(float),\n","      mode = 'lines',\n","      name = \"Market price (usd)\"\n","  )\n","\n","  trace2 = go.Scatter(\n","      x = dataset['timestamp'],\n","      y = dataset[features[0][1]].astype(float),\n","      mode = 'lines',\n","      name = features[0][0]\n","  )\n","\n","  trace3 = go.Scatter(\n","      x = dataset['timestamp'],\n","      y = dataset[features[1][1]].astype(float),\n","      mode = 'lines',\n","      name = features[1][0]\n","  )\n","\n","  trace4 = go.Scatter(\n","      x = dataset['timestamp'],\n","      y = dataset[features[2][1]].astype(float),\n","      mode = 'lines',\n","      name = features[2][0]\n","  )\n","\n","  layout = dict(\n","      title=title,\n","      xaxis=dict(\n","          rangeselector=dict(\n","              buttons=list([\n","                  # Change the count to desired amount of months.\n","                  dict(count=1,\n","                      label='1m',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=6,\n","                      label='6m',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=12,\n","                      label='1y',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(count=36,\n","                      label='3y',\n","                      step='month',\n","                      stepmode='backward'),\n","                  dict(step='all')\n","              ])\n","          ),\n","          rangeslider=dict(\n","              visible = True\n","          ),\n","          type='date'\n","      )\n","  )\n","\n","  data = [trace1, trace2, trace3, trace4]\n","\n","  fig = dict(data=data, layout=layout)\n","  iplot(fig, filename = title)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVsE5Ed_aZap"},"outputs":[],"source":["# Extract the short term SMA\n","short_term_sma = list(additional_features.items())[1:4]\n","print(short_term_sma)\n","\n","# Extract the long term SMA\n","long_term_sma = list(additional_features.items())[-3:]\n","print(long_term_sma)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O45Snn4nLv99"},"outputs":[],"source":["# Additional Features: Short term SMA\n","if SLOW_OPERATIONS:\n","  sma_visualization(merged_df_pd, short_term_sma, \"Short term SMA (usd)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFPGKfPXaXPb"},"outputs":[],"source":["# Additional Features: Long term SMA\n","if SLOW_OPERATIONS:\n","  sma_visualization(merged_df_pd,long_term_sma, \"Long term SMA (usd)\")"]},{"cell_type":"markdown","metadata":{"id":"p1Fc7fl2Lv99"},"source":["#  Feature selection\n","Here we are going to select features based on their correlation with the market price using the Pearson method.\n","\n","They were divided into 3 groups to see the differences according to their use:\n","* **All:** contains all features\n","* **Most correlated:** contains features that have a correlation value > 0.7\n","* **Least correlated:** contains the features that have a correlation value <= 0.7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pG39n7WLv99"},"outputs":[],"source":["# Use the dataset with only the features without any index\n","new_columns = [\"next-market-price\"] + [col for col in merged_df.columns if col not in [\"timestamp\", \"id\", \"next-market-price\"]]\n","merged_df_no_index = merged_df.select(*new_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnD9I1CmLv99"},"outputs":[],"source":["# First group of features: all\n","all_features = merged_df_no_index.columns[1:]\n","print(f\"Number of features: {len(all_features)}\")\n","print(all_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paP6aqjrLv99"},"outputs":[],"source":["# Assemble the features into a vector column\n","assembler = VectorAssembler(inputCols=merged_df_no_index.columns, outputCol=\"features\")\n","df_vector = assembler.transform(merged_df_no_index).select(\"next-market-price\", \"features\")\n","\n","# Calculate the correlation matrix using Pearson method\n","correlation_matrix = Correlation.corr(df_vector, \"features\", method=\"pearson\").head()\n","\n","# Get the correlation values with the \"market-price\" column\n","correlation_with_market_price = correlation_matrix[0].toArray()[0]\n","\n","# Create a dictionary with feature names and their correlation values\n","feature_correlations = dict(zip(merged_df_no_index.columns, correlation_with_market_price))\n","\n","# Sort the features based on their correlation value (from highest to lowest)\n","sorted_features = dict(sorted(feature_correlations.items(), key=lambda x: x[1], reverse=True))\n","\n","# Set the threshold value\n","threshold = 0.7\n","\n","# Show features and their correlation value according to the defined threshold\n","features_dict = {}\n","most_corr_features = []\n","least_corr_features = []\n","for feature, correlation in sorted_features.items():\n","  features_dict[feature] = correlation\n","  if (feature != 'next-market-price'):\n","    if (correlation > threshold):\n","      most_corr_features.append(feature)\n","    else:\n","      least_corr_features.append(feature)\n","\n","# Print the sorted features and their correlation values\n","features_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TBMl6rQLv99"},"outputs":[],"source":["# Second group of features: most correlated\n","print(f\"Number of features: {len(most_corr_features)}\")\n","print(most_corr_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kC5fAQVLv99"},"outputs":[],"source":["# Third group of features: least correlated\n","print(f\"Number of features: {len(least_corr_features)}\")\n","print(least_corr_features)"]},{"cell_type":"markdown","metadata":{"id":"Q1dizTOFLv99"},"source":["# Saving selected features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qs3tXlH3mozj"},"outputs":[],"source":["# Save all the features and their correlation value\n","with open(FEATURES_CORRELATION, 'w') as file:\n","    json.dump(features_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dpvj9VWzLv99"},"outputs":[],"source":["# Save sll the features\n","with open(ALL_FEATURES, 'w') as file:\n","    json.dump(all_features, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"InZ_DK88Lv9-"},"outputs":[],"source":["# Save the most correlated features\n","with open(MOST_CORR_FEATURES, 'w') as file:\n","    json.dump(most_corr_features, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAX8fLBcLv9-"},"outputs":[],"source":["# Save the least correlated features\n","with open(LEAST_CORR_FEATURES, 'w') as file:\n","    json.dump(least_corr_features, file)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
